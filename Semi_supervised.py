import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import openml
import os
import mlflow
import plotly.express as px
import shutil
import time
import torch
from torchvision import transforms
from torch.utils.data import TensorDataset, DataLoader
from datetime import datetime
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score
from mlflow.tracking import MlflowClient
from sklearn.model_selection import train_test_split 

def mlflow_input():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")

    DAGSHUB_USERNAME = "NguyenNhat248"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "Mnist"
    DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Semi-supervised")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"

def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def show_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch c√°c Runs trong MLflow v·ªõi c√°c t√πy ch·ªçn qu·∫£n l√Ω."""
    st.title("üìä Tr√¨nh qu·∫£n l√Ω MLflow Experiments")
    
    # Nh·∫≠p th√¥ng tin t·ª´ ng∆∞·ªùi d√πng
    mlflow_input()
    
    # Ch·ªçn experiment c·∫ßn hi·ªÉn th·ªã
    experiment_name = "Neural Network"
    experiments = mlflow.search_experiments()
    current_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)
    
    if not current_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return
    
    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {current_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if current_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**ƒê∆∞·ªùng d·∫´n l∆∞u tr·ªØ:** {current_experiment.artifact_location}")
    
    # L·∫•y danh s√°ch c√°c Runs
    runs = mlflow.search_runs(experiment_ids=[current_experiment.experiment_id])
    
    if runs.empty:
        st.warning("‚ö† Hi·ªán kh√¥ng c√≥ Runs n√†o trong Experiment n√†y.")
        return
    
    # X·ª≠ l√Ω th√¥ng tin Runs ƒë·ªÉ hi·ªÉn th·ªã
    run_data_list = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_metadata = mlflow.get_run(run_id)
        run_tags = run_metadata.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")
        created_time = format_time_relative(run_metadata.info.start_time)
        duration = ((run_metadata.info.end_time - run_metadata.info.start_time) / 1000) if run_metadata.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Kh√¥ng x√°c ƒë·ªãnh")

        run_data_list.append({
            "T√™n Run": run_name,
            "Run ID": run_id,
            "Th·ªùi gian t·∫°o": created_time,
            "Th·ªùi gian ch·∫°y (s)": f"{duration:.1f}s" if isinstance(duration, float) else duration,
            "Ngu·ªìn": source
        })
    
    # Hi·ªÉn th·ªã danh s√°ch Runs
    df_runs = pd.DataFrame(run_data_list).sort_values(by="Th·ªùi gian t·∫°o", ascending=False)
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch c√°c Runs:")
    st.dataframe(df_runs, use_container_width=True)
    
    # L·ª±a ch·ªçn Run ƒë·ªÉ xem chi ti·∫øt
    run_names = df_runs["T√™n Run"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)
    selected_run_id = df_runs.loc[df_runs["T√™n Run"] == selected_run_name, "Run ID"].values[0]
    selected_run = mlflow.get_run(selected_run_id)
    
    # --- Ch·ªânh s·ª≠a th√¥ng tin Run ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ T√™n Run ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ xem thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")
    
    # --- X√≥a Run ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ Run **{selected_run_name}** ƒë√£ b·ªã x√≥a! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a Run: {e}")
    
    # --- Hi·ªÉn th·ªã chi ti·∫øt Run ---
    if selected_run:
        st.subheader(f"üìå Chi ti·∫øt Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        formatted_start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"
        st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {formatted_start_time}")
        
        # Hi·ªÉn th·ªã Parameters v√† Metrics
        params = selected_run.data.params
        metrics = selected_run.data.metrics
        
        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)
        
        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)
        
        # ƒê∆∞·ªùng d·∫´n Model Artifact
        model_artifact_url = f"{st.session_state['mlflow_url']}/{current_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_url})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ªßa Run n√†y.")

def tong_quan():
    st.title("T·ªïng quan v·ªÅ b·ªô d·ªØ li·ªáu MNIST")

    st.header("1. Gi·ªõi thi·ªáu")
    st.write(
        "MNIST (Modified National Institute of Standards and Technology) l√† m·ªôt b·ªô d·ªØ li·ªáu ph·ªï bi·∫øn "
        "trong lƒ©nh v·ª±c th·ªã gi√°c m√°y t√≠nh v√† h·ªçc m√°y, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√†o t·∫°o v√† ki·ªÉm th·ª≠ c√°c "
        "thu·∫≠t to√°n nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay."
    )

    st.subheader("Th√¥ng tin ch√≠nh")
    st.write("- T·ªïng c·ªông 70.000 h√¨nh ·∫£nh grayscale c·ªßa c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.")
    st.write("- M·ªói h√¨nh c√≥ k√≠ch th∆∞·ªõc 28x28 pixel.")
    st.write("- ƒê·ªãnh d·∫°ng d·ªØ li·ªáu: Ma tr·∫≠n 28x28 v·ªõi gi√° tr·ªã pixel t·ª´ 0 (m√†u ƒëen) ƒë·∫øn 255 (m√†u tr·∫Øng).")
    st.write("- M·ªói ·∫£nh c√≥ nh√£n t∆∞∆°ng ·ª©ng l√† m·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9.")

    st.header("2. Ngu·ªìn g·ªëc v√† ·ª©ng d·ª•ng")
    st.write("- ƒê∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n b·ªô d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay c·ªßa NIST, v·ªõi s·ª± chu·∫©n b·ªã c·ªßa LeCun, Cortes v√† Burges.")
    st.write("- L√† th∆∞·ªõc ƒëo chu·∫©n cho hi·ªáu su·∫•t c·ªßa c√°c thu·∫≠t to√°n x·ª≠ l√Ω h√¨nh ·∫£nh v√† m·∫°ng n∆°-ron.")
    st.write("- ƒê∆∞·ª£c d√πng r·ªông r√£i trong nghi√™n c·ª©u v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o v√† th·ªã gi√°c m√°y t√≠nh.")

    st.header("3. C·∫•u tr√∫c t·∫≠p d·ªØ li·ªáu")
    st.write("- **T·∫≠p hu·∫•n luy·ªán:** 60.000 h√¨nh ·∫£nh.")
    st.write("- **T·∫≠p ki·ªÉm th·ª≠:** 10.000 h√¨nh ·∫£nh.")
    st.write("- C√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9 c√≥ ph√¢n b·ªë t∆∞∆°ng ƒë·ªëi ƒë·ªìng ƒë·ªÅu.")

    st.header("4. ·ª®ng d·ª•ng th·ª±c t·∫ø")
    st.write("- ƒê√†o t·∫°o m√¥ h√¨nh ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay.")
    st.write("- So s√°nh hi·ªáu su·∫•t gi·ªØa c√°c thu·∫≠t to√°n h·ªçc m√°y v√† h·ªçc s√¢u.")
    st.write("- L√†m quen v·ªõi c√°c ph∆∞∆°ng ph√°p ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

def upload_data():
    st.header("üì• T·∫£i d·ªØ li·ªáu v√†o h·ªá th·ªëng")

    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("üî∏ **D·ªØ li·ªáu ƒë√£ c√≥ s·∫µn!** B·∫°n c√≥ th·ªÉ chuy·ªÉn sang b∆∞·ªõc ti·∫øp theo.")
    else:
        data_source = st.radio("L·ª±a ch·ªçn c√°ch nh·∫≠p d·ªØ li·ªáu:", ["L·∫•y t·ª´ OpenML", "T·∫£i l√™n t·ª´ m√°y t√≠nh"], key="data_source_option")

        if "data" not in st.session_state:
            st.session_state.data = None

        if data_source == "L·∫•y t·ª´ OpenML":
            st.subheader("üìÇ Nh·∫≠p d·ªØ li·ªáu MNIST t·ª´ OpenML")
            if st.button("B·∫Øt ƒë·∫ßu t·∫£i xu·ªëng", key="download_openml"):
                with st.status("üîÑ ƒêang l·∫•y d·ªØ li·ªáu t·ª´ OpenML...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent in range(0, 101, 20):
                        time.sleep(0.5)
                        progress_bar.progress(percent)
                        status.update(label=f"üîÑ ƒêang x·ª≠ l√Ω... ({percent}%)")

                    # Gi·∫£ l·∫≠p qu√° tr√¨nh t·∫£i d·ªØ li·ªáu
                    X = np.load("X.npy")
                    y = np.load("y.npy")

                    status.update(label="‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!", state="complete")

                    st.session_state.data = (X, y)

        else:
            st.subheader("üì§ T·∫£i l√™n file c·ªßa b·∫°n")
            uploaded_file = st.file_uploader("Ch·ªçn file ·∫£nh", type=["png", "jpg", "jpeg"], key="upload_file")

            if uploaded_file is not None:
                with st.status("üîÑ ƒêang x·ª≠ l√Ω t·∫≠p tin...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent in range(0, 101, 25):
                        time.sleep(0.3)
                        progress_bar.progress(percent)
                        status.update(label=f"üîÑ ƒêang ki·ªÉm tra... ({percent}%)")

                    image = Image.open(uploaded_file).convert('L')
                    st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)

                    if image.size != (28, 28):
                        status.update(label="‚ùå K√≠ch th∆∞·ªõc ·∫£nh kh√¥ng ph√π h·ª£p! H√£y ch·ªçn ·∫£nh c√≥ k√≠ch th∆∞·ªõc 28x28 pixel.", state="error")
                    else:
                        status.update(label="‚úÖ H√¨nh ·∫£nh h·ª£p l·ªá!", state="complete")
                        transform = transforms.Compose([
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))
                        ])
                        image_tensor = transform(image).unsqueeze(0)
                        st.session_state.data = image_tensor

    if st.session_state.data is not None:
        st.subheader("‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
    else:
        st.warning("‚ö† Vui l√≤ng nh·∫≠p d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c.")

    st.markdown("""
    üîπ **L∆∞u √Ω:**  
    - Ch·ªâ h·ªó tr·ª£ ·∫£nh grayscale v·ªõi k√≠ch th∆∞·ªõc **28x28 pixel**.  
    - Khi l·∫•y d·ªØ li·ªáu t·ª´ OpenML, c·∫ßn ƒë·∫£m b·∫£o c√≥ c·ªôt **'label'** ch·ª©a nh√£n t·ª´ 0 ƒë·∫øn 9.  
    - N·∫øu file kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng, vui l√≤ng s·ª≠ d·ª•ng d·ªØ li·ªáu MNIST t·ª´ OpenML.  
    """)



def split_data():
    st.title("üìå Ph√¢n chia d·ªØ li·ªáu Train/Test")

    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ t·∫£i l√™n ch∆∞a
    if "data" not in st.session_state or st.session_state.data is None:
        st.warning("‚ö†Ô∏è H√£y nh·∫≠p d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øn h√†nh chia t·∫≠p!")
        return

    # L·∫•y d·ªØ li·ªáu t·ª´ session_state
    X, y = st.session_state.data
    total_samples = X.shape[0]

    # N·∫øu ch∆∞a c√≥ bi·∫øn c·ªù "data_split_done", thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh l√† False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu s·ª≠ d·ª•ng ƒë·ªÉ train
    num_samples = st.number_input("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán:", min_value=1000, max_value=total_samples, value=20000, step=1000)
    
    # Ch·ªçn t·ª∑ l·ªá train/test
    test_ratio = st.slider("üìå Ch·ªçn ph·∫ßn trƒÉm d·ªØ li·ªáu d√†nh cho ki·ªÉm th·ª≠", 10, 50, 20)
    train_ratio = 100 - test_ratio
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Train={train_ratio}%, Test={test_ratio}%")

    # Placeholder cho ti·∫øn tr√¨nh v√† b·∫£ng k·∫øt qu·∫£
    progress_placeholder = st.empty()
    results_table = st.empty()

    # X·ª≠ l√Ω khi nh·∫•n n√∫t x√°c nh·∫≠n
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u", key="save_split"):
        progress_placeholder.progress(10)  # Ti·∫øn tr√¨nh b·∫Øt ƒë·∫ßu
        st.session_state.data_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia t·∫≠p d·ªØ li·ªáu
        
        # L·∫•y s·ªë l∆∞·ª£ng d·ªØ li·ªáu theo y√™u c·∫ßu
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y, random_state=42
            )

        progress_placeholder.progress(40)  # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh

        # Ph√¢n chia t·∫≠p Train/Test
        stratify_condition = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train, X_test, y_train, y_test = train_test_split(
            X_selected, y_selected, test_size=test_ratio/100, stratify=stratify_condition, random_state=42
        )

        progress_placeholder.progress(70)  # Ti·∫øn tr√¨nh 70% ho√†n th√†nh

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.total_samples = num_samples
        st.session_state["neural_X_train"] = X_train
        st.session_state["neural_X_test"] = X_test
        st.session_state["neural_y_train"] = y_train
        st.session_state["neural_y_test"] = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.train_size = X_train.shape[0]

        progress_placeholder.progress(90)  # G·∫ßn ho√†n t·∫•t

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n chia
        st.session_state.summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]]
        })

        st.success("‚úÖ Ph√¢n chia d·ªØ li·ªáu th√†nh c√¥ng!")
        results_table.table(st.session_state.summary_df)
        progress_placeholder.progress(100)  # Ho√†n t·∫•t

    # N·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia tr∆∞·ªõc ƒë√≥
    if st.session_state.data_split_done:
        if "summary_df" in st.session_state:
            results_table.table(st.session_state.summary_df)
        
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n chia. Nh·∫•n n√∫t d∆∞·ªõi ƒë·ªÉ thay ƒë·ªïi n·∫øu c·∫ßn.")

        if st.button("üîÑ Chia l·∫°i d·ªØ li·ªáu", key="resplit_data"):
            progress_placeholder.progress(10)  # Ti·∫øn tr√¨nh kh·ªüi ƒë·ªông l·∫°i
            results_table.empty()

            # Ch·ªçn l·∫°i d·ªØ li·ªáu theo s·ªë l∆∞·ª£ng y√™u c·∫ßu
            if num_samples == total_samples:
                X_selected, y_selected = X, y
            else:
                X_selected, _, y_selected, _ = train_test_split(
                    X, y, train_size=num_samples, stratify=y, random_state=42
                )

            progress_placeholder.progress(40)

            # Chia train/test l·∫ßn n·ªØa
            stratify_condition = y_selected if len(np.unique(y_selected)) > 1 else None
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y_selected, test_size=test_ratio/100, stratify=stratify_condition, random_state=42
            )

            progress_placeholder.progress(70)

            # C·∫≠p nh·∫≠t l·∫°i session_state
            st.session_state.total_samples = num_samples
            st.session_state["neural_X_train"] = X_train
            st.session_state["neural_X_test"] = X_test
            st.session_state["neural_y_train"] = y_train
            st.session_state["neural_y_test"] = y_test
            st.session_state.test_size = X_test.shape[0]
            st.session_state.train_size = X_train.shape[0]

            progress_placeholder.progress(90)

            # C·∫≠p nh·∫≠t b·∫£ng k·∫øt qu·∫£ m·ªõi
            st.session_state.summary_df = pd.DataFrame({
                "T·∫≠p d·ªØ li·ªáu": ["Train", "Test"],
                "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]]
            })
            st.success("‚úÖ Ph√¢n chia l·∫°i d·ªØ li·ªáu th√†nh c√¥ng!")
            results_table.table(st.session_state.summary_df)
            progress_placeholder.progress(100)  # Ho√†n t·∫•t



#Callback phuc vu train2
class ProgressBarCallback:
    def __init__(self, total_epochs, progress_bar, status_text, max_train_progress=80):
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.max_train_progress = max_train_progress

    def on_epoch_begin(self, epoch):
        progress = (epoch + 1) / self.total_epochs * self.max_train_progress
        self.progress_bar.progress(min(int(progress), self.max_train_progress))
        self.status_text.text(f"üõ†Ô∏è ƒêang hu·∫•n luy·ªán m√¥ h√¨nh... Epoch {epoch + 1}/{self.total_epochs}")

    def on_train_end(self):
        self.progress_bar.progress(self.max_train_progress)
        self.status_text.text("‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t, ƒëang chu·∫©n b·ªã logging...")

class NeuralNet(nn.Module):
    def __init__(self, input_size, num_layers, num_nodes, activation):
        super(NeuralNet, self).__init__()
        layers = [nn.Linear(input_size, num_nodes), self.get_activation(activation)]
        
        for _ in range(num_layers - 1):
            layers.append(nn.Linear(num_nodes, num_nodes))
            layers.append(self.get_activation(activation))
        
        layers.append(nn.Linear(num_nodes, 10))  # Output layer
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

    def get_activation(self, activation):
        """ Tr·∫£ v·ªÅ h√†m k√≠ch ho·∫°t ph√π h·ª£p """
        if activation == "relu":
            return nn.ReLU()
        elif activation == "sigmoid":
            return nn.Sigmoid()
        elif activation == "tanh":
            return nn.Tanh()
        else:
            raise ValueError(f"Kh√¥ng h·ªó tr·ª£ activation: {activation}")

def pseudo_labelling():
    st.header("‚öôÔ∏è Pseudo Labelling v·ªõi M·∫°ng N∆°-ron (PyTorch)")
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia ch∆∞a
    if "neural_X_train" not in st.session_state or "neural_X_test" not in st.session_state:
        st.error("‚ö†Ô∏è D·ªØ li·ªáu ch∆∞a s·∫µn s√†ng! Vui l√≤ng th·ª±c hi·ªán chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu v·ªÅ tensor v√† chu·∫©n h√≥a
    X_train_full = torch.tensor(st.session_state["neural_X_train"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_train_full = torch.tensor(st.session_state["neural_y_train"], dtype=torch.long)
    X_test = torch.tensor(st.session_state["neural_X_test"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_test = torch.tensor(st.session_state["neural_y_test"], dtype=torch.long)
    
    # L·∫•y m·ªôt ph·∫ßn nh·ªè d·ªØ li·ªáu ban ƒë·∫ßu (~1% m·ªói l·ªõp)
    X_initial, y_initial = [], []
    for label in range(10):
        label_indices = torch.where(y_train_full == label)[0]
        sample_count = max(1, int(0.01 * len(label_indices)))
        chosen_indices = label_indices[torch.randperm(len(label_indices))[:sample_count]]
        X_initial.append(X_train_full[chosen_indices])
        y_initial.append(y_train_full[chosen_indices])
    
    X_initial = torch.cat(X_initial, dim=0)
    y_initial = torch.cat(y_initial, dim=0)
    mask = torch.ones(len(X_train_full), dtype=torch.bool)
    mask[chosen_indices] = False
    X_unlabeled = X_train_full[mask]
    
    # T√πy ch·ªçn ch·∫ø ƒë·ªô l·∫∑p
    iteration_mode = st.selectbox("Ch·∫ø ƒë·ªô l·∫∑p:", ["S·ªë v√≤ng l·∫∑p gi·ªõi h·∫°n", "G√°n to√†n b·ªô t·∫≠p train"], key="iteration_mode")
    
    max_iterations = st.slider("S·ªë v√≤ng t·ªëi ƒëa", 1, 10, 5) if iteration_mode == "S·ªë v√≤ng l·∫∑p gi·ªõi h·∫°n" else float('inf')
    if iteration_mode == "G√°n to√†n b·ªô t·∫≠p train":
        st.warning("‚ö†Ô∏è Qu√° tr√¨nh c√≥ th·ªÉ m·∫•t nhi·ªÅu th·ªùi gian do s·ªë v√≤ng l·∫∑p kh√¥ng gi·ªõi h·∫°n!")

    # C·∫•u h√¨nh m√¥ h√¨nh
    hidden_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    neurons_per_layer = st.slider("S·ªë node m·ªói l·ªõp", 32, 256, 128)
    activation_function = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"])
    training_epochs = st.slider("S·ªë epoch m·ªói v√≤ng", 1, 50, 10)
    confidence_threshold = st.slider("Ng∆∞·ª°ng g√°n nh√£n", 0.5, 1.0, 0.95, step=0.01)
    learning_rate = st.number_input("T·ªëc ƒë·ªô h·ªçc", min_value=0.0001, max_value=0.1, value=0.001, step=0.0001, format="%.4f")
    
    run_identifier = st.text_input("üîπ ƒê·∫∑t t√™n Run:", "Pseudo_Default_Run")
    
    if st.button("B·∫Øt ƒë·∫ßu Pseudo Labelling"):
        mlflow.start_run(run_name=f"Pseudo_{run_identifier}")
        model = NeuralNet(28 * 28, hidden_layers, neurons_per_layer, activation_function)
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()
        
        X_labeled, y_labeled = X_initial.clone(), y_initial.clone()
        X_unlabeled_remaining = X_unlabeled.clone()
        total_data_count = len(X_train_full)
        
        iteration = 0
        progress_bar = st.progress(0)
        status_message = st.empty()
        
        while iteration < max_iterations:
            st.write(f"### V√≤ng l·∫∑p {iteration + 1}")
            train_dataset = TensorDataset(X_labeled, y_labeled)
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            
            model.train()
            for epoch in range(training_epochs):
                status_message.text(f"üöÄ ƒêang hu·∫•n luy·ªán - Epoch {epoch + 1}/{training_epochs}...")
                progress_bar.progress(int((epoch + 1) / training_epochs * 50))
                for batch_X, batch_y in train_loader:
                    optimizer.zero_grad()
                    output = model(batch_X)
                    loss = criterion(output, batch_y)
                    loss.backward()
                    optimizer.step()
                time.sleep(0.5)  # Gi·∫£m t·∫£i cho h·ªá th·ªëng
            
            model.eval()
            with torch.no_grad():
                test_predictions = model(X_test)
                test_accuracy = (test_predictions.argmax(dim=1) == y_test).float().mean().item()
            
            st.write(f"üìä ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm th·ª≠: {test_accuracy:.4f}")
            mlflow.log_metric("pseudo_test_accuracy", test_accuracy, step=iteration)
            
            if len(X_unlabeled_remaining) == 0:
                break
            
            status_message.text("üîç ƒêang g√°n nh√£n gi·∫£ cho d·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c g√°n...")
            with torch.no_grad():
                unlabeled_outputs = model(X_unlabeled_remaining)
                probabilities, predicted_labels = unlabeled_outputs.softmax(dim=1).max(dim=1)
            
            confident_mask = probabilities >= confidence_threshold
            X_confident = X_unlabeled_remaining[confident_mask]
            y_confident = predicted_labels[confident_mask]
            
            st.write(f"S·ªë m·∫´u m·ªõi ƒë∆∞·ª£c g√°n nh√£n: {X_confident.shape[0]} (Ng∆∞·ª°ng: {confidence_threshold})")
            st.write(f"C√≤n l·∫°i ch∆∞a g√°n nh√£n: {X_unlabeled_remaining.shape[0] - X_confident.shape[0]}")
            
            if len(X_confident) == 0:
                break
            
            X_labeled = torch.cat([X_labeled, X_confident])
            y_labeled = torch.cat([y_labeled, y_confident])
            X_unlabeled_remaining = X_unlabeled_remaining[~confident_mask]
            
            labeled_fraction = X_labeled.shape[0] / total_data_count
            progress_bar.progress(min(int(50 + 50 * labeled_fraction), 100))
            status_message.text(f"üìà Ti·∫øn tr√¨nh g√°n nh√£n: {X_labeled.shape[0]}/{total_data_count} m·∫´u ({labeled_fraction:.2%})")
            
            iteration += 1
            if iteration_mode == "G√°n to√†n b·ªô t·∫≠p train" and len(X_unlabeled_remaining) == 0:
                break
        
        torch.save(model.state_dict(), "pseudo_model_final.pth")
        mlflow.log_artifact("pseudo_model_final.pth")
        mlflow.end_run()
        
        st.success("‚úÖ Pseudo Labelling ho√†n t·∫•t!")
        st.markdown(f"[üîó Truy c·∫≠p MLflow tr√™n DAGsHub]({st.session_state['mlflow_url']})")


def Semi_supervised():
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ### üñäÔ∏è MNIST NN & Semi-supervised App")
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
    ["T·ªïng quan", 
    "T·∫£i d·ªØ li·ªáu",
    "Chia d·ªØ li·ªáu",
    "Hu·∫•n luy·ªán", 
    "Th√¥ng tin hu·∫•n luy·ªán"])

    with tab1: 
        tong_quan()
    with tab2: 
        upload_data()
    with tab3: 
        split_data()
    with tab4: 
        pseudo_labelling()
    with tab5:
        show_mlflow_experiments()
        
def run():
    Semi_supervised() 

if __name__ == "__main__":
    run()
