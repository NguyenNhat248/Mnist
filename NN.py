import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
import openml
import os
import torch.nn as nn
import mlflow
import plotly.express as px
import shutil
import time
import random
from streamlit_drawable_canvas import st_canvas
from torch.utils.data import DataLoader, TensorDataset
import torch.optim as optim
import torch
from torchvision import transforms
from datetime import datetime
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from mlflow.tracking import MlflowClient
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split 



def mlflow_input():

    DAGSHUB_USERNAME = "NguyenNhat248"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "Mnist"
    DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Neural Network")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"



def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def show_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow v·ªõi giao di·ªán tr·ª±c quan."""
    st.title("üìä Tr√¨nh xem MLflow Experiments")
    
    # Nh·∫≠p th√¥ng tin MLflow
    mlflow_input()
    
    # X√°c ƒë·ªãnh t√™n experiment
    exp_name = "Neural Network"
    exp_list = mlflow.search_experiments()
    chosen_exp = next((e for e in exp_list if e.name == exp_name), None)
    
    if not chosen_exp:
        st.error(f"‚ùå Experiment '{exp_name}' kh√¥ng t·ªìn t·∫°i!")
        return
    
    # Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n
    st.subheader(f"üìå Experiment: {exp_name}")
    st.write(f"**Experiment ID:** {chosen_exp.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if chosen_exp.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**L∆∞u tr·ªØ t·∫°i:** {chosen_exp.artifact_location}")
    
    # Truy xu·∫•t danh s√°ch Runs
    runs_df = mlflow.search_runs(experiment_ids=[chosen_exp.experiment_id])
    if runs_df.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return
    
    # X·ª≠ l√Ω d·ªØ li·ªáu Runs
    run_data = []
    for _, run in runs_df.iterrows():
        run_id = run["run_id"]
        run_details = mlflow.get_run(run_id)
        run_name = run_details.data.tags.get("mlflow.runName", f"Run {run_id[:8]}")
        created_time = format_time_relative(run_details.info.start_time)
        duration = (run_details.info.end_time - run_details.info.start_time) / 1000 if run_details.info.end_time else "ƒêang ch·∫°y"
        source = run_details.data.tags.get("mlflow.source.name", "Unknown")
        
        run_data.append({
            "T√™n Run": run_name,
            "Run ID": run_id,
            "T·∫°o l√∫c": created_time,
            "Th·ªùi gian (s)": f"{duration:.1f}s" if isinstance(duration, float) else duration,
            "Ngu·ªìn": source
        })
    
    run_df = pd.DataFrame(run_data).sort_values(by="T·∫°o l√∫c", ascending=False)
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_df, use_container_width=True)
    
    # Ch·ªçn Run c·ª• th·ªÉ ƒë·ªÉ xem
    run_choices = run_df["T√™n Run"].tolist()
    chosen_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_choices)
    chosen_run_id = run_df.loc[run_df["T√™n Run"] == chosen_run_name, "Run ID"].values[0]
    chosen_run = mlflow.get_run(chosen_run_id)
    
    # Ch·ªânh s·ª≠a t√™n Run
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", chosen_run_name)
    if st.button("üíæ L∆∞u thay ƒë·ªïi"):
        try:
            mlflow.set_tag(chosen_run_id, "mlflow.runName", new_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_name}**. Vui l√≤ng t·∫£i l·∫°i trang!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")
    
    # X√≥a Run
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(chosen_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{chosen_run_name}**! Vui l√≤ng t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")
    
    # Hi·ªÉn th·ªã th√¥ng tin Run chi ti·∫øt
    if chosen_run:
        st.subheader(f"üìå Th√¥ng tin Run: {chosen_run_name}")
        st.write(f"**Run ID:** {chosen_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {chosen_run.info.status}")
        
        start_time_ms = chosen_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng r√µ"
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")
        
        # Hi·ªÉn th·ªã th√¥ng s·ªë
        if chosen_run.data.params:
            st.write("### ‚öôÔ∏è Th√¥ng s·ªë:")
            st.json(chosen_run.data.params)
        if chosen_run.data.metrics:
            st.write("### üìä Ch·ªâ s·ªë:")
            st.json(chosen_run.data.metrics)
        
        # Hi·ªÉn th·ªã model artifact
        model_path = f"{st.session_state['mlflow_url']}/{chosen_exp.experiment_id}/{chosen_run_id}/artifacts/model"
        st.write("### üìÇ M√¥ h√¨nh:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

def upload_data():
    """Ch·ª©c nƒÉng t·∫£i l√™n ho·∫∑c t·∫£i xu·ªëng d·ªØ li·ªáu."""
    st.header("üì• T·∫£i d·ªØ li·ªáu v√†o h·ªá th·ªëng")
    
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("üî∏ **D·ªØ li·ªáu ƒë√£ c√≥ s·∫µn!** B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c c√°c b∆∞·ªõc ti·∫øp theo.")
    else:
        source_choice = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["T·∫£i t·ª´ OpenML", "T·∫£i l√™n t·ª´ m√°y"])
        
        if "data" not in st.session_state:
            st.session_state.data = None
        
        if source_choice == "T·∫£i t·ª´ OpenML":
            st.markdown("#### üìÇ T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML")
            if st.button("T·∫£i d·ªØ li·ªáu MNIST"):
                with st.status("üîÑ ƒêang t·∫£i d·ªØ li·ªáu t·ª´ OpenML...", expanded=True) as status:
                    progress = st.progress(0)
                    for percent in range(0, 101, 20):
                        time.sleep(0.5)
                        progress.progress(percent)
                        status.update(label=f"üîÑ ƒêang t·∫£i... ({percent}%)")
                    
                    X = np.load("X.npy")
                    y = np.load("y.npy")
                    
                    status.update(label="‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!", state="complete")
                    st.session_state.data = (X, y)
        
        else:
            st.markdown("#### üì§ T·∫£i ·∫£nh t·ª´ thi·∫øt b·ªã")
            uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh c·∫ßn t·∫£i l√™n", type=["png", "jpg", "jpeg"])
            
            if uploaded_file is not None:
                with st.status("üîÑ ƒêang ki·ªÉm tra v√† x·ª≠ l√Ω ·∫£nh...", expanded=True) as status:
                    progress = st.progress(0)
                    for percent in range(0, 101, 25):
                        time.sleep(0.3)
                        progress.progress(percent)
                        status.update(label=f"üîÑ ƒêang x·ª≠ l√Ω... ({percent}%)")
                    
                    image = Image.open(uploaded_file).convert('L')
                    st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)
                    
                    if image.size != (28, 28):
                        status.update(label="‚ùå ·∫¢nh kh√¥ng ƒë√∫ng k√≠ch th∆∞·ªõc y√™u c·∫ßu (28x28 px).", state="error")
                    else:
                        status.update(label="‚úÖ ·∫¢nh h·ª£p l·ªá!", state="complete")
                        transform = transforms.Compose([
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))
                        ])
                        st.session_state.data = transform(image).unsqueeze(0)
    
    if st.session_state.data is not None:
        st.markdown("#### ‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
    else:
        st.warning("üî∏ H√£y t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c.")
    
    st.markdown("""
    üîπ **L∆∞u √Ω:**
    - Ch·ªâ ch·∫•p nh·∫≠n ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28x28 pixel (grayscale)**.
    - Khi t·∫£i d·ªØ li·ªáu t·ª´ OpenML, c·∫ßn c√≥ c·ªôt **'label'** ƒë·ªÉ ph√¢n lo·∫°i s·ªë t·ª´ 0 ƒë·∫øn 9.
    - N·∫øu d·ªØ li·ªáu kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng, vui l√≤ng s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu MNIST.
    """)
def split_data():
    """Chia t·∫≠p d·ªØ li·ªáu th√†nh Train, Validation v√† Test."""
    st.markdown("### üìå Chia d·ªØ li·ªáu Train/Test")
    
    if "data" not in st.session_state or st.session_state.data is None:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi chia t·∫≠p.")
        return
    
    X, y = st.session_state.data
    total_samples = X.shape[0]
    
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False
    
    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ Train:", 1000, total_samples, min(10000, total_samples))
    test_size = st.slider("üìå Ch·ªçn t·ª∑ l·ªá Test (%):", 10, 50, 20)
    val_size = st.slider("üìå Ch·ªçn t·ª∑ l·ªá Validation (% trong Train):", 0, 50, 15)
    st.write(f"üìå **T·ª∑ l·ªá chia:** Test={test_size}%, Validation={val_size}%, Train={100 - test_size - val_size}%")
    
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True
        
        progress = st.progress(0)
        status = st.empty()
        
        status.text("üîÑ ƒêang ch·ªçn d·ªØ li·ªáu (0%)")
        
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y if len(np.unique(y)) > 1 else None, random_state=42
            )
        
        progress.progress(25)
        status.text("üîÑ ƒêang chia Train/Test (50%)")
        
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size / 100, stratify=y_selected if len(np.unique(y_selected)) > 1 else None, random_state=42
        )
        
        progress.progress(50)
        status.text("üîÑ ƒêang chia Train/Validation (75%)")
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_size / (100 - test_size),
            stratify=y_train_full if len(np.unique(y_train_full)) > 1 else None, random_state=42
        )
        
        progress.progress(75)
        
        st.session_state.update({
            "total_samples": num_samples,
            "X_train": X_train,
            "X_val": X_val,
            "X_test": X_test,
            "y_train": y_train,
            "y_val": y_val,
            "y_test": y_test,
            "test_size": X_test.shape[0],
            "val_size": X_val.shape[0],
            "train_size": X_train.shape[0]
        })
        
        progress.progress(100)
        status.text("‚úÖ Chia d·ªØ li·ªáu ho√†n t·∫•t (100%)")
        
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)
    
    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")

class NeuralNet(nn.Module):
    def __init__(self, input_size, num_layers, num_nodes, activation):
        super(NeuralNet, self).__init__()
        layers = [nn.Linear(input_size, num_nodes), activation()]
        for _ in range(num_layers - 1):
            layers.append(nn.Linear(num_nodes, num_nodes))
            layers.append(activation())
        layers.append(nn.Linear(num_nodes, 10))  # Output layer (10 classes)
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

def train():
    if "mlflow_url" not in st.session_state:
        st.session_state["mlflow_url"] = "https://dagshub.com/Snxtruc/HocMayPython.mlflow"

    mlflow_input()

    if not all(k in st.session_state for k in ["X_train", "X_val", "X_test"]):
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh tensor
    X_train = torch.tensor(st.session_state["X_train"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    X_val = torch.tensor(st.session_state["X_val"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32) if st.session_state["X_val"].size > 0 else None
    X_test = torch.tensor(st.session_state["X_test"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_train = torch.tensor(st.session_state["y_train"], dtype=torch.long)
    y_val = torch.tensor(st.session_state["y_val"], dtype=torch.long) if X_val is not None else None
    y_test = torch.tensor(st.session_state["y_test"], dtype=torch.long)

    # Chia batch ƒë·ªÉ hu·∫•n luy·ªán th·ª±c t·∫ø h∆°n
    batch_size = 64
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # Giao di·ªán t√πy ch·ªânh m√¥ h√¨nh
    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")
    num_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    num_nodes = st.slider("S·ªë node m·ªói l·ªõp", 32, 256, 128)
    activation_func = st.selectbox("H√†m k√≠ch ho·∫°t", ["ReLU", "Sigmoid", "Tanh"])
    optimizer_choice = st.selectbox("Optimizer", ["Adam", "SGD", "RMSprop"])
    learning_rate = st.slider("Learning Rate", 1e-5, 1e-1, 1e-3, format="%.5f")
    epochs = st.slider("S·ªë epoch", 1, 50, 10)
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run")
    st.session_state["run_name"] = run_name if run_name else "default_run"

    activation_dict = {"ReLU": nn.ReLU, "Sigmoid": nn.Sigmoid, "Tanh": nn.Tanh}
    activation = activation_dict[activation_func]
    
    model = NeuralNet(28 * 28, num_layers, num_nodes, activation)
    criterion = nn.CrossEntropyLoss()

    optimizer_dict = {
        "Adam": optim.Adam(model.parameters(), lr=learning_rate),
        "SGD": optim.SGD(model.parameters(), lr=learning_rate),
        "RMSprop": optim.RMSprop(model.parameters(), lr=learning_rate),
    }
    optimizer = optimizer_dict[optimizer_choice]

    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_params({
                "num_layers": num_layers,
                "num_nodes": num_nodes,
                "activation": activation_func,
                "optimizer": optimizer_choice,
                "learning_rate": learning_rate,
                "epochs": epochs,
            })

            progress_bar = st.progress(0)
            status_text = st.empty()

            train_losses = []
            val_accuracies = []

            for epoch in range(epochs):
                model.train()
                epoch_loss = 0
                for batch_X, batch_y in train_loader:
                    optimizer.zero_grad()
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item()

                train_losses.append(epoch_loss / len(train_loader))

                model.eval()
                with torch.no_grad():
                    val_acc = None
                    if X_val is not None:
                        val_preds = model(X_val).argmax(dim=1)
                        val_acc = (val_preds == y_val).float().mean().item()
                        val_accuracies.append(val_acc)

                progress = int((epoch + 1) / epochs * 100)
                progress_bar.progress(progress / 100)

                if val_acc is not None:
                    status_text.text(f"üõ†Ô∏è Epoch {epoch + 1}/{epochs} | Loss: {train_losses[-1]:.4f} | Val Acc: {val_acc:.4f} | {progress}%")
                else:
                    status_text.text(f"üõ†Ô∏è Epoch {epoch + 1}/{epochs} | Loss: {train_losses[-1]:.4f} | {progress}%")
                
                time.sleep(0.5)

            model.eval()
            with torch.no_grad():
                train_acc = (model(X_train).argmax(dim=1) == y_train).float().mean().item()
                test_acc = (model(X_test).argmax(dim=1) == y_test).float().mean().item()
                val_acc = np.mean(val_accuracies) if val_accuracies else None

            if val_acc is not None:
                st.success(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation**: {val_acc:.4f}")
                st.success(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train**: {train_acc:.4f}")

            mlflow.log_metrics({
                "train_accuracy": train_acc,
                "test_accuracy": test_acc,
                "final_train_loss": train_losses[-1],
            })
            if val_acc is not None:
                mlflow.log_metric("val_accuracy", val_acc)

            # üî• G·ªçi h√†m l∆∞u model
            save_model(model, num_layers, num_nodes, activation_func)

            progress_bar.progress(1.0)
            status_text.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
            st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")

# ‚úÖ H√ÄM M·ªöI: Save Model
def save_model(model, num_layers, num_nodes, activation_func):
    model_name = f"{st.session_state['run_name']}_{num_layers}layers_{num_nodes}nodes_{activation_func}"
    
    # Tr√°nh tr√πng t√™n model
    if "neural_models" not in st.session_state:
        st.session_state["neural_models"] = []

    existing_names = {m["name"] for m in st.session_state["neural_models"]}
    while model_name in existing_names:
        model_name += "_new"

    model_path = f"{model_name}.pth"
    torch.save({
        "num_layers": num_layers,
        "num_nodes": num_nodes,
        "activation_func": activation_func,
        "model_state_dict": model.state_dict()
    }, model_path)
    
    st.session_state["neural_models"].append({"name": model_name, "model": model_path})
    st.session_state["trained_model"] = model  # ‚úÖ Load ngay v√†o session_state
    st.success(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh: `{model_name}`")



# H√†m x·ª≠ l√Ω ·∫£nh
def preprocess_canvas_image(canvas_result):
    # Ki·ªÉm tra n·∫øu canvas tr·ªëng
    if canvas_result is None or canvas_result.image_data is None:
        return None

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ canvas th√†nh numpy array
    image_array = np.array(canvas_result.image_data, dtype=np.uint8)

    # ƒê·∫£m b·∫£o ·∫£nh c√≥ ƒë√∫ng 3 k√™nh (RGB), n·∫øu kh√¥ng, chuy·ªÉn ƒë·ªïi
    if image_array.shape[-1] == 4:  # N·∫øu c√≥ k√™nh Alpha (RGBA), lo·∫°i b·ªè
        image_array = image_array[:, :, :3]

    # Chuy·ªÉn numpy array th√†nh ·∫£nh PIL
    image_pil = Image.fromarray(image_array)

    # Chuy·ªÉn sang ·∫£nh x√°m (grayscale) v√† resize v·ªÅ 28x28
    image_pil = ImageOps.grayscale(image_pil)  
    image_pil = image_pil.resize((28, 28))  

    # Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh tensor ƒë·ªÉ ƒë∆∞a v√†o model
    transform = transforms.Compose([
        transforms.ToTensor(),  
        transforms.Normalize((0.5,), (0.5,))  
    ])
    
    image_tensor = transform(image_pil).view(-1, 28 * 28)  
    return image_tensor


def preprocess_image(canvas_result):
    if canvas_result is None or canvas_result.image_data is None:
        return None
    
    image_array = np.array(canvas_result.image_data, dtype=np.uint8)
    if image_array.shape[-1] == 4:
        image_array = image_array[:, :, :3]
    
    image_pil = Image.fromarray(image_array)
    image_pil = ImageOps.grayscale(image_pil)  # Chuy·ªÉn sang grayscale
    image_pil = image_pil.resize((28, 28))  # Resize v·ªÅ 28x28
    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    
    image_tensor = transform(image_pil).view(-1, 28 * 28)
    return image_tensor

def demo():
    st.title("üîç Tr√¨nh nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay")
    st.write("V·∫Ω m·ªôt s·ªë b·∫•t k·ª≥ t·ª´ 0 ƒë·∫øn 9, sau ƒë√≥ nh·∫•n **D·ª± ƒëo√°n** ƒë·ªÉ xem k·∫øt qu·∫£!")
    
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("‚úÖ M√¥ h√¨nh ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng!")
    else:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh! H√£y hu·∫•n luy·ªán tr∆∞·ªõc.")
        return
    
    if "canvas_key" not in st.session_state:
        st.session_state.canvas_key = str(random.randint(0, 1000000))
    
    if st.button("üîÑ T·∫£i l·∫°i canvas"):
        st.session_state.canvas_key = str(random.randint(0, 1000000))
    
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.canvas_key,
        update_streamlit=True
    )
    
    if st.button("üöÄ D·ª± ƒëo√°n"):
        img = preprocess_image(canvas_result)
        if img is not None:
            st.image(
                Image.fromarray((img.numpy().reshape(28, 28) * 255).astype(np.uint8)), 
                caption="·∫¢nh ƒë√£ x·ª≠ l√Ω", 
                width=100
            )
            
            model.eval()
            with torch.no_grad():
                logits = model(img)
                prediction = logits.argmax(dim=1).item()
                confidence_scores = torch.nn.functional.softmax(logits, dim=1)
                max_confidence = confidence_scores.max().item()
            
            col1, col2 = st.columns(2)
            col1.metric("üî¢ S·ªë d·ª± ƒëo√°n", prediction)
            col2.metric("üìä ƒê·ªô tin c·∫≠y", f"{max_confidence:.2%}")
            
            fig, ax = plt.subplots()
            labels = [str(i) for i in range(10)]
            ax.bar(labels, confidence_scores.numpy().flatten(), color="skyblue")
            ax.set_xlabel("S·ªë d·ª± ƒëo√°n")
            ax.set_ylabel("M·ª©c ƒë·ªô tin c·∫≠y")
            ax.set_title("Bi·ªÉu ƒë·ªì ph√¢n b·ªë x√°c su·∫•t")
            st.pyplot(fig)
        else:
            st.error("‚ö†Ô∏è Vui l√≤ng v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

def NeuralNetwork():
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown("### üñäÔ∏è MNIST Neural Network App")

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "T·ªïng quan",
        "T·∫£i d·ªØ li·ªáu",
        "Chia d·ªØ li·ªáu",
        "Hu·∫•n luy·ªán",
        "Th√¥ng tin hu·∫•n luy·ªán",
        "Demo"
    ])

    with tab2:
        upload_data()
    with tab3:
        split_data()
    with tab4:
        train()
    with tab5:
        show_mlflow_experiments()
    with tab6:
        demo()

def run():
    NeuralNetwork()

if __name__ == "__main__":
    run()
