import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import openml
import os
import mlflow
import time
import shutil
import humanize
from datetime import datetime
from scipy.stats import mode
from scipy import stats
from mlflow.tracking import MlflowClient
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML


import streamlit as st

def ly_thuyet_kmeans():
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» K-Means")
    
    st.subheader("1ï¸âƒ£ K-Means lÃ  gÃ¬?")
    st.write("K-means lÃ  má»™t thuáº­t toÃ¡n **há»c khÃ´ng giÃ¡m sÃ¡t** dÃ¹ng Ä‘á»ƒ phÃ¢n cá»¥m dá»¯ liá»‡u thÃ nh k cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch Euclid.")
    
    st.subheader("ğŸ¯ Má»¥c tiÃªu cá»§a thuáº­t toÃ¡n K-Means")
    st.write("Thuáº­t toÃ¡n **K-Means** tÃ¬m cÃ¡c cá»¥m tá»‘i Æ°u trong táº­p dá»¯ liá»‡u báº±ng cÃ¡ch tá»‘i thiá»ƒu hÃ³a tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch tá»« cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº¿n tÃ¢m cá»¥m cá»§a chÃºng.")
    
    st.subheader("HÃ m má»¥c tiÃªu (Objective Function)")
    st.latex(r"""
    J = \sum_{k=1}^{K} \sum_{x_i \in C_k} || x_i - \mu_k ||^2
    """)
    
    st.write("Trong Ä‘Ã³:")
    st.write("- \( K \): Sá»‘ lÆ°á»£ng cá»¥m.")
    st.write("- \( C_k \): Táº­p há»£p cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thuá»™c cá»¥m thá»© \( k \).")
    st.write("- \( x_i \): Äiá»ƒm dá»¯ liá»‡u trong cá»¥m \( C_k \).")
    st.write("- \( \mu_k \): TÃ¢m cá»¥m cá»§a \( C_k \).")
    st.write("- \( || x_i - \mu_k ||^2 \): Khoáº£ng cÃ¡ch Euclidean bÃ¬nh phÆ°Æ¡ng giá»¯a Ä‘iá»ƒm \( x_i \) vÃ  tÃ¢m cá»¥m \( \mu_k \).")
    
    st.subheader("2ï¸âƒ£ Ã tÆ°á»Ÿng")
    st.write("- Chia táº­p dá»¯ liá»‡u thÃ nh \( K \) cá»¥m, vá»›i má»—i cá»¥m cÃ³ má»™t tÃ¢m cá»¥m.")
    st.write("- Dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m cÃ³ tÃ¢m cá»¥m gáº§n nháº¥t.")
    st.write("- Cáº­p nháº­t tÃ¢m cá»¥m báº±ng cÃ¡ch tÃ­nh trung bÃ¬nh cÃ¡c Ä‘iá»ƒm thuá»™c cá»¥m.")
    st.write("- Láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng cÃ³ sá»± thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ trong cá»¥m.")
    
    st.subheader("3ï¸âƒ£ Thuáº­t toÃ¡n K-Means")
    st.write("1. Chá»n sá»‘ cá»¥m \( K \) (Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c).")
    st.write("2. Khá»Ÿi táº¡o \( K \) tÃ¢m cá»¥m (chá»n ngáº«u nhiÃªn hoáº·c theo K-Means++).")
    st.write("3. GÃ¡n dá»¯ liá»‡u vÃ o cá»¥m: Má»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m cÃ³ tÃ¢m cá»¥m gáº§n nháº¥t.")
    st.latex(r"""d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}""")
    st.write("4. Cáº­p nháº­t tÃ¢m cá»¥m: TÃ­nh láº¡i tÃ¢m cá»¥m báº±ng cÃ¡ch láº¥y trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong má»—i cá»¥m.")
    st.latex(r"""\mu_k = \frac{1}{N_k} \sum_{i=1}^{N_k} x_i""")
    st.write("5. Láº·p láº¡i bÆ°á»›c 3 & 4 cho Ä‘áº¿n khi cÃ¡c tÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i nhiá»u ná»¯a hoáº·c Ä‘áº¡t Ä‘áº¿n sá»‘ láº§n láº·p tá»‘i Ä‘a.")
    
    st.subheader("4ï¸âƒ£ ÄÃ¡nh giÃ¡ thuáº­t toÃ¡n K-Means")
    
    st.write("**ğŸ“Œ Elbow Method**")
    st.write("- TÃ­nh tá»•ng khoáº£ng cÃ¡ch ná»™i cá»¥m WCSS (Within-Cluster Sum of Squares) cho cÃ¡c giÃ¡ trá»‹ k khÃ¡c nhau.")
    st.write("- Äiá»ƒm \"khuá»·u tay\" (elbow point) lÃ  giÃ¡ trá»‹ k tá»‘i Æ°u, táº¡i Ä‘Ã³ viá»‡c tÄƒng thÃªm cá»¥m khÃ´ng lÃ m giáº£m Ä‘Ã¡ng ká»ƒ WCSS.")
    st.latex(r"""
    WCSS = \sum_{i=1}^{k} \sum_{x \in C_i} \|x - \mu_i\|^2
    """)
    
    st.write("**ğŸ“Œ Silhouette Score**")
    st.write("- So sÃ¡nh má»©c Ä‘á»™ gáº§n gÅ©i giá»¯a cÃ¡c Ä‘iá»ƒm trong cá»¥m vá»›i cÃ¡c Ä‘iá»ƒm á»Ÿ cá»¥m khÃ¡c.")
    st.latex(r"""
    s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
    """)
    st.write("Trong Ä‘Ã³:")
    st.write("- \( a(i) \): Khoáº£ng cÃ¡ch trung bÃ¬nh tá»« Ä‘iá»ƒm \( i \) Ä‘áº¿n cÃ¡c Ä‘iá»ƒm trong cÃ¹ng cá»¥m.")
    st.write("- \( b(i) \): Khoáº£ng cÃ¡ch trung bÃ¬nh tá»« Ä‘iá»ƒm \( i \) Ä‘áº¿n cÃ¡c Ä‘iá»ƒm trong cá»¥m gáº§n nháº¥t.")
    
    st.write("**ğŸ“Œ Gap Statistic**")
    st.write("- So sÃ¡nh hiá»‡u quáº£ phÃ¢n cá»¥m trÃªn dá»¯ liá»‡u thá»±c vá»›i dá»¯ liá»‡u ngáº«u nhiÃªn (khÃ´ng cÃ³ cáº¥u trÃºc).")
    st.latex(r"""
    Gap(k) = \mathbb{E}[\log(W_k^{random})] - \log(W_k^{data})
    """)
    st.write("Trong Ä‘Ã³:")
    st.write("- \( W_k^{random} \): WCSS trÃªn random data.")
    st.write("- \( W_k^{data} \): WCSS trÃªn actual data.")

def ly_thuyet_dbscans():
    st.header("ğŸ“– TÃ¬m hiá»ƒu vá» DBSCAN")
    
    st.markdown("### 1ï¸âƒ£ DBSCAN lÃ  gÃ¬?")
    st.write("DBSCAN (Density-Based Spatial Clustering of Applications with Noise) lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™. NÃ³ Ä‘áº·c biá»‡t há»¯u Ã­ch khi lÃ m viá»‡c vá»›i cÃ¡c cá»¥m cÃ³ hÃ¬nh dáº¡ng khÃ´ng xÃ¡c Ä‘á»‹nh vÃ  cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n Ä‘iá»ƒm nhiá»…u (outlier).")
    
    st.markdown("#### ğŸ”¹ Äáº·c Ä‘iá»ƒm chÃ­nh cá»§a DBSCAN")
    st.write("- **KhÃ´ng cáº§n xÃ¡c Ä‘á»‹nh trÆ°á»›c sá»‘ cá»¥m** nhÆ° K-Means.")
    st.write("- **Xá»­ lÃ½ tá»‘t dá»¯ liá»‡u cÃ³ nhiá»…u** báº±ng cÃ¡ch Ä‘Ã¡nh dáº¥u cÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c cá»¥m nÃ o.")
    st.write("- **CÃ³ thá»ƒ phÃ¡t hiá»‡n cá»¥m vá»›i hÃ¬nh dáº¡ng báº¥t ká»³**, khÃ´ng bá»‹ giá»›i háº¡n vÃ o cÃ¡c hÃ¬nh cáº§u nhÆ° K-Means.")
    
    st.markdown("### 2ï¸âƒ£ CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a DBSCAN")
    
    st.markdown("#### ğŸ”¹ CÃ¡c tham sá»‘ quan trá»ng")
    st.write("- **Epsilon (Îµ):** XÃ¡c Ä‘á»‹nh bÃ¡n kÃ­nh Ä‘á»ƒ kiá»ƒm tra lÃ¢n cáº­n cá»§a má»™t Ä‘iá»ƒm.")
    st.write("- **MinPts:** Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu trong bÃ¡n kÃ­nh Îµ Ä‘á»ƒ má»™t Ä‘iá»ƒm Ä‘Æ°á»£c coi lÃ  Ä‘iá»ƒm lÃµi.")
    
    st.markdown("#### ğŸ”¹ PhÃ¢n loáº¡i Ä‘iá»ƒm trong DBSCAN")
    st.write("- **Core Point (Äiá»ƒm lÃµi):** CÃ³ Ã­t nháº¥t MinPts Ä‘iá»ƒm náº±m trong vÃ¹ng Îµ.")
    st.write("- **Border Point (Äiá»ƒm biÃªn):** Náº±m trong vÃ¹ng Îµ cá»§a má»™t Ä‘iá»ƒm lÃµi nhÆ°ng khÃ´ng cÃ³ Ä‘á»§ MinPts Ä‘á»ƒ trá»Ÿ thÃ nh Ä‘iá»ƒm lÃµi.")
    st.write("- **Noise (Äiá»ƒm nhiá»…u):** KhÃ´ng thuá»™c vÃ o báº¥t ká»³ cá»¥m nÃ o.")
    
    st.markdown("### 3ï¸âƒ£ Thuáº­t toÃ¡n DBSCAN")
    st.write("1. Chá»n má»™t Ä‘iá»ƒm chÆ°a Ä‘Æ°á»£c kiá»ƒm tra.")
    st.write("2. Kiá»ƒm tra xem Ä‘iá»ƒm Ä‘Ã³ cÃ³ Ã­t nháº¥t MinPts Ä‘iá»ƒm lÃ¢n cáº­n trong bÃ¡n kÃ­nh Îµ khÃ´ng:")
    st.write("   - Náº¿u cÃ³: Äiá»ƒm nÃ y trá»Ÿ thÃ nh **core point**, báº¯t Ä‘áº§u má»™t cá»¥m má»›i.")
    st.write("   - Náº¿u khÃ´ng: Äiá»ƒm nÃ y lÃ  **noise**. Tuy nhiÃªn, náº¿u nÃ³ thuá»™c vÃ¹ng lÃ¢n cáº­n cá»§a má»™t Ä‘iá»ƒm lÃµi khÃ¡c, nÃ³ cÃ³ thá»ƒ trá»Ÿ thÃ nh **border point**.")
    st.write("3. Náº¿u tÃ¬m tháº¥y core point, má»Ÿ rá»™ng cá»¥m báº±ng cÃ¡ch thÃªm táº¥t cáº£ cÃ¡c Ä‘iá»ƒm lÃ¢n cáº­n vÃ o cá»¥m.")
    st.write("4. Tiáº¿p tá»¥c quÃ¡ trÃ¬nh vá»›i cÃ¡c Ä‘iá»ƒm chÆ°a Ä‘Æ°á»£c kiá»ƒm tra cho Ä‘áº¿n khi táº¥t cáº£ cÃ¡c Ä‘iá»ƒm Ä‘Æ°á»£c xá»­ lÃ½.")
    
    st.markdown("### 4ï¸âƒ£ ÄÃ¡nh giÃ¡ thuáº­t toÃ¡n DBSCAN")
    
    st.markdown("#### ğŸ”¹ Æ¯u Ä‘iá»ƒm")
    st.write("- KhÃ´ng yÃªu cáº§u sá»‘ lÆ°á»£ng cá»¥m trÆ°á»›c.")
    st.write("- Nháº­n diá»‡n Ä‘Æ°á»£c cá»¥m cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³.")
    st.write("- Tá»‘t trong viá»‡c xá»­ lÃ½ dá»¯ liá»‡u cÃ³ nhiá»…u.")
    
    st.markdown("#### ğŸ”¹ NhÆ°á»£c Ä‘iá»ƒm")
    st.write("- Lá»±a chá»n tham sá»‘ Îµ vÃ  MinPts cÃ³ thá»ƒ khÃ³ khÄƒn.")
    st.write("- Hiá»‡u suáº¥t kÃ©m vá»›i dá»¯ liá»‡u cÃ³ máº­t Ä‘á»™ khÃ´ng Ä‘á»“ng Ä‘á»u.")




def data(): 
    st.title("ğŸ“š Giá»›i Thiá»‡u Táº­p Dá»¯ Liá»‡u MNIST")

    st.markdown("""
    Táº­p dá»¯ liá»‡u **MNIST (Modified National Institute of Standards and Technology)** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u quan trá»ng nháº¥t trong lÄ©nh vá»±c há»c mÃ¡y, Ä‘áº·c biá»‡t lÃ  trong bÃ i toÃ¡n nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay. Bá»™ dá»¯ liá»‡u nÃ y thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i hÃ¬nh áº£nh.

    ## 1ï¸âƒ£ Tá»•ng Quan Vá» Táº­p Dá»¯ Liá»‡u MNIST
    MNIST bao gá»“m hÃ¬nh áº£nh cÃ¡c chá»¯ sá»‘ tá»« **0 Ä‘áº¿n 9**, Ä‘Æ°á»£c viáº¿t tay bá»Ÿi nhiá»u ngÆ°á»i khÃ¡c nhau. CÃ¡c hÃ¬nh áº£nh Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a vá» kÃ­ch thÆ°á»›c vÃ  Ä‘á»™ sÃ¡ng, giÃºp thuáº­n tiá»‡n hÆ¡n trong quÃ¡ trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u.  

    Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c chia thÃ nh hai pháº§n chÃ­nh:
    - **Táº­p huáº¥n luyá»‡n:** 60.000 hÃ¬nh áº£nh.
    - **Táº­p kiá»ƒm tra:** 10.000 hÃ¬nh áº£nh.  
      
    Má»—i hÃ¬nh áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i **28x28 pixel**, vá»›i giÃ¡ trá»‹ cÆ°á»ng Ä‘á»™ sÃ¡ng tá»« **0 Ä‘áº¿n 255** (0 lÃ  mÃ u Ä‘en, 255 lÃ  mÃ u tráº¯ng).

    ## 2ï¸âƒ£ Má»¥c ÄÃ­ch Sá»­ Dá»¥ng MNIST
    Bá»™ dá»¯ liá»‡u nÃ y thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ:  
    - **Huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay**.
    - **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t thuáº­t toÃ¡n há»c mÃ¡y**, tá»« phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng nhÆ° KNN, SVM Ä‘áº¿n máº¡ng nÆ¡-ron nhÃ¢n táº¡o (ANN) vÃ  máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN).
    - **LÃ m quen vá»›i xá»­ lÃ½ áº£nh sá»‘** vÃ  cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ nhÆ° chuáº©n hÃ³a dá»¯ liá»‡u, trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng.

    ## 3ï¸âƒ£ Cáº¥u TrÃºc Dá»¯ Liá»‡u
    Má»—i hÃ¬nh áº£nh trong MNIST cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng ma tráº­n **28x28**, tÆ°Æ¡ng á»©ng vá»›i **784 giÃ¡ trá»‹ sá»‘**. Khi lÃ m viá»‡c vá»›i dá»¯ liá»‡u nÃ y, cÃ³ thá»ƒ:
    - **Chuyá»ƒn Ä‘á»•i ma tráº­n thÃ nh vector 1 chiá»u** Ä‘á»ƒ Ä‘Æ°a vÃ o mÃ´ hÃ¬nh há»c mÃ¡y.
    - **Ãp dá»¥ng ká»¹ thuáº­t giáº£m chiá»u dá»¯ liá»‡u** nhÆ° PCA Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t mÃ´ hÃ¬nh.
    
    ## 4ï¸âƒ£ á»¨ng Dá»¥ng Cá»§a MNIST
    MNIST Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong:
    - **Nháº­n dáº¡ng chá»¯ viáº¿t tay**, á»©ng dá»¥ng trong Ä‘á»c sá»‘ tá»« áº£nh chá»¥p hoáº·c tÃ i liá»‡u sá»‘ hÃ³a.
    - **NghiÃªn cá»©u vá» máº¡ng nÆ¡-ron**, giÃºp kiá»ƒm thá»­ cÃ¡c kiáº¿n trÃºc má»›i nhÆ° CNN, GANs.
    - **Há»c táº­p vÃ  thá»±c hÃ nh AI**, lÃ  bÃ i toÃ¡n khá»Ÿi Ä‘áº§u quen thuá»™c cho nhá»¯ng ai má»›i tiáº¿p cáº­n há»c sÃ¢u.

    """)



def up_load_db():
    st.header("ğŸ“¥ Táº£i Dá»¯ Liá»‡u")

    # Kiá»ƒm tra náº¿u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i trÆ°á»›c Ä‘Ã³
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("ğŸ”¹ **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn!** Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i bÆ°á»›c tiá»n xá»­ lÃ½.")
    else:
        option = st.radio("ğŸ“Œ Chá»n nguá»“n dá»¯ liá»‡u:", ["Táº£i tá»« OpenML", "Táº£i lÃªn tá»« thiáº¿t bá»‹"], key="data_source_radio")

        if "data" not in st.session_state:
            st.session_state.data = None

        # TrÆ°á»ng há»£p táº£i dá»¯ liá»‡u tá»« OpenML
        if option == "Táº£i tá»« OpenML":
            st.subheader("ğŸ“‚ Táº£i dá»¯ liá»‡u MNIST tá»« OpenML")
            if st.button("ğŸ“¥ Báº¯t Ä‘áº§u táº£i dá»¯ liá»‡u MNIST", key="download_mnist_button"):
                with st.status("ğŸ”„ Äang táº£i dá»¯ liá»‡u MNIST...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent in range(0, 101, 20):
                        time.sleep(0.5)
                        progress_bar.progress(percent)
                        status.update(label=f"ğŸ”„ Äang táº£i... ({percent}%)")

                    # Táº£i dá»¯ liá»‡u tá»« file Ä‘Ã£ lÆ°u sáºµn
                    X = np.load("X.npy")
                    y = np.load("y.npy")

                    status.update(label="âœ… Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng!", state="complete")
                    st.session_state.data = (X, y)

        # TrÆ°á»ng há»£p ngÆ°á»i dÃ¹ng muá»‘n táº£i lÃªn dá»¯ liá»‡u cá»§a há»
        else:
            st.subheader("ğŸ“¤ Táº£i lÃªn dá»¯ liá»‡u cá»§a báº¡n")
            uploaded_file = st.file_uploader("ğŸ“Œ Chá»n má»™t file áº£nh (PNG, JPG, JPEG)", 
                                             type=["png", "jpg", "jpeg"], 
                                             key="file_upload")

            if uploaded_file is not None:
                with st.status("ğŸ”„ Äang xá»­ lÃ½ áº£nh...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent in range(0, 101, 25):
                        time.sleep(0.3)
                        progress_bar.progress(percent)
                        status.update(label=f"ğŸ”„ Äang xá»­ lÃ½... ({percent}%)")

                    image = Image.open(uploaded_file)
                    st.image(image, caption="ğŸ“· áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

                    # Kiá»ƒm tra kÃ­ch thÆ°á»›c áº£nh
                    if image.size != (28, 28):
                        status.update(label="âŒ áº¢nh khÃ´ng Ä‘Ãºng kÃ­ch thÆ°á»›c 28x28 pixel.", state="error")
                    else:
                        status.update(label="âœ… áº¢nh há»£p lá»‡!", state="complete")
                        image = image.convert('L')  # Chuyá»ƒn sang áº£nh xÃ¡m
                        image_array = np.array(image).reshape(1, -1)
                        st.session_state.data = image_array

    # Náº¿u dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng, tiáº¿n hÃ nh tiá»n xá»­ lÃ½
    if st.session_state.data is not None:
        st.subheader("âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng!")

        if isinstance(st.session_state.data, tuple):
            X, y = st.session_state.data
            st.subheader("ğŸ”„ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST")
            preprocess_option = st.selectbox("ğŸ“Œ Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½:", 
                                            ["Chuáº©n hÃ³a (Standardization)", "Giáº£m chiá»u (PCA)", "Giá»¯ nguyÃªn"], 
                                            key="preprocess_mnist")

            if preprocess_option == "Chuáº©n hÃ³a (Standardization)":
                X_reshaped = X.reshape(X.shape[0], -1)
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X_reshaped)
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi chuáº©n hÃ³a:**")
                st.write(pd.DataFrame(X_scaled).head())

            elif preprocess_option == "Giáº£m chiá»u (PCA)":
                pca = PCA(n_components=50)
                X_pca = pca.fit_transform(X.reshape(X.shape[0], -1))
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi giáº£m chiá»u (PCA):**")
                st.write(pd.DataFrame(X_pca).head())

            else:
                st.write("ğŸ“Š **Dá»¯ liá»‡u giá»¯ nguyÃªn, khÃ´ng cÃ³ tiá»n xá»­ lÃ½.**")

        elif isinstance(st.session_state.data, np.ndarray):
            st.subheader("ğŸ‘ï¸ Tiá»n xá»­ lÃ½ áº£nh")
            preprocess_option_image = st.selectbox("ğŸ“Œ Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ áº£nh:",
                                                   ["Chuáº©n hÃ³a áº£nh", "Giá»¯ nguyÃªn"], 
                                                   key="preprocess_image")

            if preprocess_option_image == "Chuáº©n hÃ³a áº£nh":
                image_scaled = st.session_state.data / 255.0
                st.write("ğŸ“Š **áº¢nh sau khi chuáº©n hÃ³a:**")
                st.image(image_scaled.reshape(28, 28), caption="áº¢nh sau khi chuáº©n hÃ³a", use_column_width=True)
            else:
                st.write("ğŸ“Š **áº¢nh giá»¯ nguyÃªn, khÃ´ng cÃ³ tiá»n xá»­ lÃ½.**")
    else:
        st.warning("ğŸ”¸ Vui lÃ²ng táº£i dá»¯ liá»‡u trÆ°á»›c khi tiáº¿p tá»¥c.")

    st.markdown("""
    ğŸ”¹ **LÆ°u Ã½:**
    - Dá»¯ liá»‡u áº£nh pháº£i cÃ³ kÃ­ch thÆ°á»›c **28x28 pixel (grayscale)**.
    - Náº¿u táº£i tá»« OpenML, dá»¯ liá»‡u cáº§n cÃ³ cá»™t **'label'** (sá»‘ tá»« 0 Ä‘áº¿n 9).
    - Náº¿u dá»¯ liá»‡u khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng, hÃ£y sá»­ dá»¥ng táº­p dá»¯ liá»‡u MNIST cÃ³ sáºµn.
    """)



import os
import time
import numpy as np
import streamlit as st
import mlflow
from sklearn.model_selection import train_test_split

def chia_du_lieu():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Táº£i dá»¯ liá»‡u MNIST
    Xmt = np.load("X.npy")
    ymt = np.load("y.npy")
    X = Xmt.reshape(Xmt.shape[0], -1)  # Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u
    y = ymt.reshape(-1)  

    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh dÃ¹ng Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 
                            min_value=1000, max_value=total_samples, value=10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n tá»· lá»‡ test:", 
                          min_value=0.1, max_value=0.5, value=0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        progress_bar = st.progress(0)
        status_text = st.empty()

        # Cáº­p nháº­t tiáº¿n trÃ¬nh tá»«ng bÆ°á»›c
        progress_stages = [
            (10, "ğŸ”„ Äang chá»n sá»‘ lÆ°á»£ng áº£nh..."),
            (50, "ğŸ”„ Äang chia dá»¯ liá»‡u Train/Test..."),
            (80, "ğŸ”„ Äang lÆ°u dá»¯ liá»‡u vÃ o session..."),
            (100, "âœ… HoÃ n táº¥t!")
        ]

        for progress, message in progress_stages:
            progress_bar.progress(progress)
            status_text.text(f"{message} ({progress}%)")
            time.sleep(0.5)  # Táº¡o Ä‘á»™ trá»… Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿n trÃ¬nh rÃµ rÃ ng hÆ¡n

        # Chia dá»¯ liá»‡u
        X_selected, y_selected = X[:num_samples], y[:num_samples]
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, 
                                                            test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"âœ… **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia:** Train ({len(X_train)}), Test ({len(X_test)})")

    if "X_train" in st.session_state:
        st.write("ğŸ“Œ **Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!**")

# ğŸ› ï¸ Thiáº¿t láº­p MLflow Tracking vá»›i DAGsHub (áº©n Access Token)
def mlflow_input():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    DAGSHUB_USERNAME = "NguyenNhat248"  # Thay báº±ng username cá»§a báº¡n
    DAGSHUB_REPO_NAME = "Mnist"
    DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay báº±ng Access Token cá»§a báº¡n

    # Äáº·t URI MLflow Ä‘á»ƒ trá» Ä‘áº¿n DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thiáº¿t láº­p authentication báº±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # Äáº·t thÃ­ nghiá»‡m MLflow
    mlflow.set_experiment("Clustering Algorithms")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


def train():
    st.header("âš™ï¸ Lá»±a chá»n thuáº­t toÃ¡n & Báº¯t Ä‘áº§u huáº¥n luyá»‡n")

    # Kiá»ƒm tra dá»¯ liá»‡u trÆ°á»›c khi huáº¥n luyá»‡n
    if "X_train" not in st.session_state:
        st.warning("âš ï¸ Vui lÃ²ng thá»±c hiá»‡n bÆ°á»›c chia dá»¯ liá»‡u trÆ°á»›c khi tiáº¿p tá»¥c!")
        return

    # TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« session_state
    X_train = st.session_state["X_train"]
    y_train = st.session_state["y_train"]
    X_train_prepared = (X_train / 255.0).reshape(X_train.shape[0], -1)  # Chuáº©n hÃ³a dá»¯ liá»‡u

    # Chá»n mÃ´ hÃ¬nh cáº§n sá»­ dá»¥ng
    model_option = st.selectbox("ğŸ” Lá»±a chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])
    run_label = st.text_input("ğŸ“Œ Äáº·t tÃªn cho phiÃªn cháº¡y:", "Run_ML").strip()

    if model_option == "K-Means":
        st.subheader("ğŸ”¹ MÃ´ hÃ¬nh K-Means Clustering")
        cluster_count = st.slider("ğŸ“Š Sá»‘ cá»¥m (K):", min_value=2, max_value=20, value=10)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_prepared)
        model = KMeans(n_clusters=cluster_count, random_state=42, n_init=10)

    elif model_option == "DBSCAN":
        st.subheader("ğŸ› ï¸ MÃ´ hÃ¬nh DBSCAN Clustering")
        epsilon = st.slider("ğŸ“ GiÃ¡ trá»‹ eps (BÃ¡n kÃ­nh lÃ¢n cáº­n):", min_value=0.1, max_value=10.0, value=0.5)
        min_samples = st.slider("ğŸ”¢ Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m:", min_value=2, max_value=20, value=5)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_prepared)
        model = DBSCAN(eps=epsilon, min_samples=min_samples)

    mlflow_input()  # Káº¿t ná»‘i vá»›i MLflow

    if st.button("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n"):
        progress = st.progress(0)
        status_message = st.empty()

        with mlflow.start_run(run_name=run_label):
            for step in range(0, 101, 10):
                time.sleep(0.5)
                progress.progress(step)
                status_message.text(f"ğŸ”„ Äang huáº¥n luyá»‡n... {step}% hoÃ n thÃ nh")

            model.fit(X_train_pca)
            progress.progress(100)
            status_message.text("âœ… HoÃ n thÃ nh quÃ¡ trÃ¬nh huáº¥n luyá»‡n!")

            labels = model.labels_

            if model_option == "K-Means":
                label_dict = {}
                for i in range(cluster_count):
                    mask = labels == i
                    if np.sum(mask) > 0:
                        common_label = stats.mode(y_train[mask], keepdims=True).mode[0]
                        label_dict[i] = common_label

                predicted_labels = np.array([label_dict[label] for label in labels])
                train_accuracy = np.mean(predicted_labels == y_train)
                st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p huáº¥n luyá»‡n:** `{train_accuracy * 100:.2f}%`")

                # LÆ°u thÃ´ng tin vÃ o MLflow
                mlflow.log_param("model", "K-Means")
                mlflow.log_param("clusters", cluster_count)
                mlflow.log_metric("train_accuracy", train_accuracy)
                mlflow.sklearn.log_model(model, "kmeans_model")

            elif model_option == "DBSCAN":
                total_clusters = len(set(labels) - {-1})
                noise_percentage = np.sum(labels == -1) / len(labels)
                st.write(f"ğŸ” **Sá»‘ cá»¥m tÃ¬m tháº¥y:** `{total_clusters}`")
                st.write(f"ğŸš¨ **Tá»‰ lá»‡ Ä‘iá»ƒm nhiá»…u:** `{noise_percentage * 100:.2f}%`")

                # LÆ°u thÃ´ng tin vÃ o MLflow
                mlflow.log_param("model", "DBSCAN")
                mlflow.log_param("eps", epsilon)
                mlflow.log_param("min_samples", min_samples)
                mlflow.log_metric("total_clusters", total_clusters)
                mlflow.log_metric("noise_ratio", noise_percentage)
                mlflow.sklearn.log_model(model, "dbscan_model")

            if "models" not in st.session_state:
                st.session_state["models"] = []

            # LÆ°u láº¡i mÃ´ hÃ¬nh vÃ o session_state
            st.session_state["models"].append({"name": run_label, "model": model})
            st.success(f"âœ… MÃ´ hÃ¬nh `{run_label}` Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng!")

            # Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ train
            st.write("ğŸ“‹ **Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:**")
            for m in st.session_state["models"]:
                st.write(f"ğŸ”¹ {m['name']}")

            mlflow.end_run()
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow Ä‘á»ƒ xem káº¿t quáº£]({st.session_state['mlflow_url']})")


def du_doan():
    st.header("ğŸ” Dá»± Ä‘oÃ¡n Cá»¥m tá»« áº¢nh hoáº·c CSV")

    # Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a mÃ´ hÃ¬nh vÃ  nhÃ£n cá»¥m
    if "cluster_model" in st.session_state and "cluster_labels" in st.session_state:
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i lÃªn áº£nh (28x28, grayscale) hoáº·c file CSV", type=["png", "jpg", "csv"])
        actual_label = st.text_input("âœï¸ Nháº­p nhÃ£n thá»±c táº¿ (náº¿u cÃ³):")

        if uploaded_file is not None:
            if uploaded_file.name.endswith(".csv"):
                # Xá»­ lÃ½ tá»‡p CSV
                data = pd.read_csv(uploaded_file)
                img_vector = data.iloc[0].values.flatten() / 255.0  # Chuáº©n hÃ³a dá»¯ liá»‡u
            else:
                # Xá»­ lÃ½ tá»‡p áº£nh
                image = Image.open(uploaded_file).convert("L").resize((28, 28))
                img_vector = np.array(image).flatten() / 255.0  # Chuyá»ƒn Ä‘á»•i thÃ nh vector 1D

            if st.button("ğŸš€ Tiáº¿n hÃ nh dá»± Ä‘oÃ¡n"):
                model = st.session_state["cluster_model"]

                if isinstance(model, KMeans):
                    cluster_id = model.predict([img_vector])[0]
                elif isinstance(model, DBSCAN):
                    # Dá»± Ä‘oÃ¡n cá»¥m báº±ng cÃ¡ch tÃ¬m Ä‘iá»ƒm gáº§n nháº¥t trong dá»¯ liá»‡u Ä‘Ã£ phÃ¢n cá»¥m
                    distances = np.linalg.norm(model.components_ - img_vector, axis=1)
                    cluster_id = model.labels_[np.argmin(distances)]

                # Láº¥y thÃ´ng tin nhÃ£n cá»¥m tá»« session_state
                cluster_labels = st.session_state["cluster_labels"]
     


def format_time_relative(timestamp_ms):
    """Chuyá»ƒn timestamp milliseconds thÃ nh thá»i gian dá»… Ä‘á»c."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Giao diá»‡n quáº£n lÃ½ MLflow Experiments."""
    st.title("ğŸ“Š Theo dÃµi MLflow Experiments")

    mlflow_input()

    # XÃ¡c Ä‘á»‹nh experiment cáº§n hiá»ƒn thá»‹
    experiment_name = "Clustering Algorithms"
    experiments = mlflow.search_experiments()
    experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not experiment:
        st.error(f"ğŸš« Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"ğŸ†” **Experiment ID:** `{experiment.experiment_id}`")
    st.write(f"ğŸ“Œ **Tráº¡ng thÃ¡i:** {'Hoáº¡t Ä‘á»™ng' if experiment.lifecycle_stage == 'active' else 'ÄÃ£ xÃ³a'}")
    st.write(f"ğŸ“‚ **LÆ°u trá»¯ táº¡i:** `{experiment.artifact_location}`")

    # Láº¥y danh sÃ¡ch Runs
    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])

    if runs.empty:
        st.warning("âš  ChÆ°a cÃ³ run nÃ o trong experiment nÃ y.")
        return

    # Xá»­ lÃ½ thÃ´ng tin runs
    run_data = []
    for _, run in runs.iterrows():
        run_info = mlflow.get_run(run["run_id"])
        run_name = run_info.data.tags.get("mlflow.runName", f"Run {run['run_id'][:8]}")
        start_time = format_time_relative(run_info.info.start_time)
        duration = ((run_info.info.end_time - run_info.info.start_time) / 1000) if run_info.info.end_time else "Äang cháº¡y"
        source = run_info.data.tags.get("mlflow.source.name", "KhÃ´ng rÃµ")

        run_data.append({
            "TÃªn Run": run_name,
            "Run ID": run["run_id"],
            "Báº¯t Ä‘áº§u": start_time,
            "Thá»i gian (s)": f"{duration:.1f}s" if isinstance(duration, float) else duration,
            "Nguá»“n": source
        })

    # Sáº¯p xáº¿p runs theo thá»i gian gáº§n nháº¥t
    run_df = pd.DataFrame(run_data).sort_values(by="Báº¯t Ä‘áº§u", ascending=False)

    # Hiá»ƒn thá»‹ danh sÃ¡ch Runs
    st.write("### ğŸƒâ€â™‚ï¸ Danh sÃ¡ch Runs")
    st.dataframe(run_df, use_container_width=True)

    # Chá»n má»™t Run Ä‘á»ƒ xem chi tiáº¿t
    selected_run_name = st.selectbox("ğŸ” Chá»n Run:", run_df["TÃªn Run"])
    selected_run_id = run_df.loc[run_df["TÃªn Run"] == selected_run_name, "Run ID"].values[0]
    selected_run = mlflow.get_run(selected_run_id)

    # --- ğŸ“ Äá»”I TÃŠN RUN ---
    st.write("### âœï¸ Äá»•i tÃªn Run")
    new_name = st.text_input("Nháº­p tÃªn má»›i:", selected_run_name)
    if st.button("ğŸ’¾ LÆ°u thay Ä‘á»•i"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_name)
            st.success(f"âœ… ÄÃ£ Ä‘á»•i tÃªn thÃ nh **{new_name}**! HÃ£y táº£i láº¡i trang Ä‘á»ƒ cáº­p nháº­t.")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi Ä‘á»•i tÃªn: {e}")

    # --- ğŸ—‘ï¸ XÃ“A RUN ---
    st.write("### âŒ XÃ³a Run")
    if st.button("ğŸ—‘ï¸ XÃ³a Run nÃ y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"âœ… Run **{selected_run_name}** Ä‘Ã£ bá»‹ xÃ³a!")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi xÃ³a run: {e}")

    # --- HIá»‚N THá»Š CHI TIáº¾T RUN ---
    if selected_run:
        st.subheader(f"ğŸ“Œ Chi tiáº¿t Run: {selected_run_name}")
        st.write(f"ğŸ†” **Run ID:** `{selected_run_id}`")
        st.write(f"ğŸ“Œ **Tráº¡ng thÃ¡i:** `{selected_run.info.status}`")
        st.write(f"ğŸ•’ **Thá»i gian báº¯t Ä‘áº§u:** `{format_time_relative(selected_run.info.start_time)}`")

        # Hiá»ƒn thá»‹ Parameters vÃ  Metrics
        if selected_run.data.params:
            st.write("### âš™ï¸ Tham sá»‘:")
            st.json(selected_run.data.params)

        if selected_run.data.metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(selected_run.data.metrics)

        # Hiá»ƒn thá»‹ link táº£i mÃ´ hÃ¬nh náº¿u cÃ³
        model_url = f"{st.session_state['mlflow_url']}/{experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### ğŸ“‚ Tá»‡p mÃ´ hÃ¬nh:")
        st.write(f"ğŸ“¥ [Táº£i xuá»‘ng mÃ´ hÃ¬nh]({model_url})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho Run nÃ y.")



def ClusteringAlgorithms():
    # CSS TÃ¹y chá»‰nh Ä‘á»ƒ thiáº¿t káº¿ giao diá»‡n Ä‘áº¹p hÆ¡n
    st.markdown(
        """
        <style>
        .custom-tabs {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            justify-content: center;
        }
        .custom-tab {
            padding: 10px 15px;
            border-radius: 8px;
            cursor: pointer;
            background: #f8f9fa;
            transition: background 0.3s ease, transform 0.2s ease;
        }
        .custom-tab:hover {
            background: #e9ecef;
            transform: scale(1.05);
        }
        .custom-tab-selected {
            background: #007bff;
            color: white;
            font-weight: bold;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ğŸ¨ MNIST Clustering App")

    # Chá»n tab báº±ng radio button thay vÃ¬ tabs máº·c Ä‘á»‹nh
    tab_options = [
        "ğŸ“˜ K-MEANS", "ğŸ“˜ DBSCAN", "ğŸ“Š Dá»¯ liá»‡u", "ğŸ“¥ Táº£i dá»¯ liá»‡u",
        "ğŸ”€ Chia dá»¯ liá»‡u", "ğŸ¤– PhÃ¢n cá»¥m", "ğŸ” Káº¿t quáº£"
    ]
    
    # Hiá»ƒn thá»‹ tab lá»±a chá»n vá»›i radio button Ä‘á»ƒ táº¡o tráº£i nghiá»‡m khÃ¡c
    selected_tab = st.radio("ğŸ”¹ Chá»n má»™t má»¥c:", tab_options, horizontal=True)

    # Hiá»ƒn thá»‹ ná»™i dung theo tab Ä‘Æ°á»£c chá»n
    st.markdown("<div class='custom-tabs'>", unsafe_allow_html=True)
    
    if selected_tab == "ğŸ“˜ K-MEANS":
        ly_thuyet_kmeans()

    elif selected_tab == "ğŸ“˜ DBSCAN":
        ly_thuyet_dbscans()

    elif selected_tab == "ğŸ“Š Dá»¯ liá»‡u":
        data()

    elif selected_tab == "ğŸ“¥ Táº£i dá»¯ liá»‡u":
        up_load_db()

    elif selected_tab == "ğŸ”€ Chia dá»¯ liá»‡u":
        chia_du_lieu()

    elif selected_tab == "ğŸ¤– PhÃ¢n cá»¥m":
        train()

    elif selected_tab == "ğŸ” Káº¿t quáº£":
        display_mlflow_experiments()

    st.markdown("</div>", unsafe_allow_html=True)


def run():
    ClusteringAlgorithms()

if __name__ == "__main__":
    run()
