import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import openml
import joblib
import shutil
import cv2
import pandas as pd
import time
import os
import mlflow
import humanize
from skimage.transform import resize
from datetime import datetime
from sklearn import datasets
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from streamlit_drawable_canvas import st_canvas
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps
from mlflow.tracking import MlflowClient


def ly_thuyet_Decision_tree():
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ Decision Tree") 

    st.markdown("### 1Ô∏è‚É£ Decision Tree l√† g√¨?")
    st.write("""
    Decision Tree (C√¢y quy·∫øt ƒë·ªãnh) l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t ƒë∆∞·ª£c s·ª≠ d·ª•ng trong **ph√¢n lo·∫°i (classification)** v√† **h·ªìi quy (regression)**.
    N√≥ ho·∫°t ƒë·ªông b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh c√°c nh√≥m nh·ªè h∆°n d·ª±a tr√™n c√°c ƒëi·ªÅu ki·ªán ƒë∆∞·ª£c thi·∫øt l·∫≠p t·∫°i c√°c **n√∫t (nodes)** c·ªßa c√¢y.
    """)

    st.markdown("### 2Ô∏è‚É£ √ù t∆∞·ªüng") 
    st.markdown("""
    **2.1 V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt:**  
    - X√°c ƒë·ªãnh th·ª© t·ª± thu·ªôc t√≠nh ƒë·ªÉ chia d·ªØ li·ªáu.
    - Do c√≥ nhi·ªÅu thu·ªôc t√≠nh v√† gi√° tr·ªã kh√°c nhau, t√¨m gi·∫£i ph√°p t·ªëi ∆∞u to√†n c·ª•c l√† kh√¥ng kh·∫£ thi.
    - Gi·∫£i ph√°p: **Ph∆∞∆°ng ph√°p tham lam (greedy)** ‚Üí Ch·ªçn thu·ªôc t√≠nh **t·ªët nh·∫•t** t·∫°i m·ªói b∆∞·ªõc d·ª±a tr√™n ti√™u ch√≠ nh·∫•t ƒë·ªãnh.
    """)

    st.markdown("""
    **2.2 Qu√° tr√¨nh chia nh·ªè d·ªØ li·ªáu:**  
    - D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh **child node** d·ª±a tr√™n thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn.
    - L·∫∑p l·∫°i qu√° tr√¨nh n√†y cho ƒë·∫øn khi ƒë·∫°t ƒëi·ªÅu ki·ªán d·ª´ng.
    """)

    st.markdown("""
    **2.3 H√†m s·ªë Entropy:**  
    - Entropy ƒëo **ƒë·ªô h·ªón lo·∫°n (impurity)** c·ªßa t·∫≠p d·ªØ li·ªáu.
    - C√¥ng th·ª©c:
    """)
    st.latex(r"H(p) = - \sum_{i=1}^{n} p_i \log(p_i)")
    
    st.markdown("""
    **√ù nghƒ©a c·ªßa Entropy trong ph√¢n ph·ªëi x√°c su·∫•t:**  
    - **Entropy = 0** khi t·∫≠p d·ªØ li·ªáu ch·ªâ ch·ª©a m·ªôt nh√£n duy nh·∫•t (ƒë·ªô ch·∫Øc ch·∫Øn cao).  
    - **Entropy cao** khi d·ªØ li·ªáu ph√¢n b·ªë ƒë·ªìng ƒë·ªÅu gi·ªØa nhi·ªÅu nh√£n (ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn l·ªõn).
    """)

    st.markdown("### 3Ô∏è‚É£ Thu·∫≠t to√°n ID3")
    st.markdown("**T√≠nh to√°n Entropy t·∫°i m·ªôt Node:**")
    st.latex(r"H(S) = - \sum_{c=1}^{C} \frac{N_c}{N} \log \left(\frac{N_c}{N} \right)")

    st.markdown("**Entropy sau khi ph√¢n chia theo thu·ªôc t√≠nh x:**")
    st.latex(r"H(x,S) = \sum_{k=1}^{K} \frac{m_k}{N} H(S_k)")

    st.markdown("**Information Gain ‚Äì Ti√™u ch√≠ ch·ªçn thu·ªôc t√≠nh:**")
    st.latex(r"G(x,S) = H(S) - H(x,S)")

    st.markdown("ID3 ch·ªçn thu·ªôc t√≠nh \\( x^* \\) sao cho **Information Gain** l·ªõn nh·∫•t:")
    st.latex(r"x^* = \arg\max_{x} G(x,S) = \arg\min_{x} H(x,S)")

    st.markdown("""
    **Khi n√†o d·ª´ng ph√¢n chia?**  
    - ‚úÖ T·∫•t c·∫£ d·ªØ li·ªáu trong node thu·ªôc c√πng m·ªôt class.  
    - ‚úÖ Kh√¥ng c√≤n thu·ªôc t√≠nh n√†o ƒë·ªÉ chia ti·∫øp.  
    - ‚úÖ S·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu trong node qu√° nh·ªè.
    """)



def ly_thuyet_SVM():
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ SVM")

    st.markdown("### 1Ô∏è‚É£ SVM l√† g√¨?")
    st.write("""
    - Support Vector Machine (SVM) l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t d√πng cho **ph√¢n lo·∫°i** v√† **h·ªìi quy**.
    - M·ª•c ti√™u c·ªßa SVM l√† t√¨m ra **si√™u ph·∫≥ng t·ªëi ∆∞u** ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu v·ªõi **kho·∫£ng c√°ch l·ªÅ (margin)** l·ªõn nh·∫•t.
    """)

    st.markdown("### 2Ô∏è‚É£ √ù t∆∞·ªüng c·ªßa SVM")

    st.markdown("#### 2.1 T√¨m si√™u ph·∫≥ng ph√¢n t√°ch t·ªëi ∆∞u")
    st.write("""
    M·ªôt si√™u ph·∫≥ng (hyperplane) trong kh√¥ng gian ƒë·∫∑c tr∆∞ng c√≥ d·∫°ng:
    """)
    st.latex(r"w \cdot x + b = 0")

    st.write("""
    Trong ƒë√≥:
    - $w$ l√† vector ph√°p tuy·∫øn c·ªßa si√™u ph·∫≥ng.
    - $x$ l√† ƒëi·ªÉm d·ªØ li·ªáu.
    - $b$ l√† h·ªá s·ªë ƒëi·ªÅu ch·ªânh ƒë·ªô d·ªãch chuy·ªÉn c·ªßa si√™u ph·∫≥ng.

    M·ª•c ti√™u c·ªßa SVM l√† t√¨m si√™u ph·∫≥ng c√≥ kho·∫£ng c√°ch l·ªõn nh·∫•t t·ªõi c√°c ƒëi·ªÉm g·∫ßn nh·∫•t thu·ªôc hai l·ªõp kh√°c nhau (c√°c support vectors).
    """)

    st.markdown("#### 2.2 T·ªëi ƒëa h√≥a l·ªÅ (Maximum Margin)")
    st.write("""
    L·ªÅ (margin) l√† kho·∫£ng c√°ch gi·ªØa si√™u ph·∫≥ng v√† c√°c ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t thu·ªôc hai l·ªõp.  
    SVM c·ªë g·∫Øng **t·ªëi ƒëa h√≥a l·ªÅ** ƒë·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh c√≥ kh·∫£ nƒÉng t·ªïng qu√°t h√≥a t·ªët nh·∫•t.
    """)

    st.latex(r"D = \frac{|w^T x_0 + b|}{||w||_2}")

    st.markdown("""
    **Trong ƒë√≥:**
    - $w^T x_0$ l√† t√≠ch v√¥ h∆∞·ªõng gi·ªØa vector ph√°p tuy·∫øn c·ªßa si√™u ph·∫≥ng v√† ƒëi·ªÉm $x_0$.
    - $||w||_2$ l√† ƒë·ªô d√†i (norm) c·ªßa vector ph√°p tuy·∫øn $w$, ƒë∆∞·ª£c t√≠nh b·∫±ng:
    """)
    st.latex(r"||w||_2 = \sqrt{w_1^2 + w_2^2 + \dots + w_n^2}")

    st.markdown("#### 2.3 Khi d·ªØ li·ªáu kh√¥ng t√°ch ƒë∆∞·ª£c tuy·∫øn t√≠nh")
    st.write("""
    - Trong tr∆∞·ªùng h·ª£p d·ªØ li·ªáu kh√¥ng th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh, SVM s·ª≠ d·ª•ng **h√†m kernel** ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu sang kh√¥ng gian b·∫≠c cao h∆°n.
    """)

    st.markdown("#### C√°c kernel ph·ªï bi·∫øn:")
    st.write("""
    - **Linear Kernel**: S·ª≠ d·ª•ng khi d·ªØ li·ªáu c√≥ th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh.
    - **Polynomial Kernel**: √Ånh x·∫° d·ªØ li·ªáu sang kh√¥ng gian b·∫≠c cao h∆°n.
    - **RBF (Radial Basis Function) Kernel**: T·ªët cho d·ªØ li·ªáu phi tuy·∫øn t√≠nh.
    - **Sigmoid Kernel**: M√¥ ph·ªèng nh∆∞ m·∫°ng neural.
    """)

    st.markdown("#### 2.4 V·ªã tr√≠ t∆∞∆°ng ƒë·ªëi v·ªõi si√™u ph·∫≥ng")
    st.write("""
    - **N·∫øu** $w^T x + b > 0$: ƒêi·ªÉm $x$ thu·ªôc **l·ªõp d∆∞∆°ng**.
    - **N·∫øu** $w^T x + b < 0$: ƒêi·ªÉm $x$ thu·ªôc **l·ªõp √¢m**.
    - **N·∫øu** $w^T x + b = 0$: ƒêi·ªÉm $x$ n·∫±m **tr√™n si√™u ph·∫≥ng ph√¢n t√°ch**.
    """)



def data():
    st.title("üîç Kh√°m Ph√° T·∫≠p D·ªØ Li·ªáu MNIST")
    
    # Gi·ªõi thi·ªáu t·ªïng quan
    st.header("üìå Gi·ªõi thi·ªáu")
    st.write(
        "T·∫≠p d·ªØ li·ªáu MNIST (Modified National Institute of Standards and Technology) "
        "l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t trong lƒ©nh v·ª±c Machine Learning v√† Nh·∫≠n d·∫°ng h√¨nh ·∫£nh. "
        "N√≥ ch·ª©a c√°c ch·ªØ s·ªë vi·∫øt tay, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ th·ª≠ nghi·ªám c√°c thu·∫≠t to√°n ph√¢n lo·∫°i."
    )
    
    st.image("https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp", use_container_width=True)
    
    # Th√¥ng tin chi ti·∫øt v·ªÅ d·ªØ li·ªáu
    st.subheader("üìÇ Th√¥ng tin chi ti·∫øt")
    st.markdown(
        "- **T·ªïng s·ªë ·∫£nh:** 70.000 ·∫£nh s·ªë vi·∫øt tay (0 - 9)\n"
        "- **K√≠ch th∆∞·ªõc ·∫£nh:** 28x28 pixel (grayscale)\n"
        "- **D·ªØ li·ªáu ·∫£nh:** M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi ma tr·∫≠n 28x28 v·ªõi gi√° tr·ªã pixel t·ª´ 0 ƒë·∫øn 255\n"
        "- **Nh√£n:** S·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9 t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë th·ª±c t·∫ø"
    )
    
    # L·ªãch s·ª≠ & ·ª©ng d·ª•ng
    st.header("üìú Ngu·ªìn g·ªëc & ·ª®ng d·ª•ng")
    st.write(
        "B·ªô d·ªØ li·ªáu MNIST ƒë∆∞·ª£c ph√°t tri·ªÉn t·ª´ d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay g·ªëc c·ªßa NIST, "
        "v√† ƒë∆∞·ª£c chu·∫©n b·ªã b·ªüi Yann LeCun, Corinna Cortes, v√† Christopher Burges."
    )
    
    st.subheader("üìå ·ª®ng d·ª•ng ch√≠nh")
    st.markdown(
        "- ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y v√† h·ªçc s√¢u.\n"
        "- Ki·ªÉm th·ª≠ thu·∫≠t to√°n nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay.\n"
        "- Th·ª±c h√†nh x·ª≠ l√Ω ·∫£nh, ph√¢n lo·∫°i, v√† h·ªçc m√°y.\n"
        "- So s√°nh c√°c ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† m√¥ h√¨nh h·ªçc s√¢u."
    )
    
    # Ph√¢n chia d·ªØ li·ªáu
    st.header("üìä C·∫•u tr√∫c T·∫≠p D·ªØ Li·ªáu")
    st.markdown(
        "- **T·∫≠p hu·∫•n luy·ªán:** 60.000 ·∫£nh ƒë·ªÉ d·∫°y m√¥ h√¨nh.\n"
        "- **T·∫≠p ki·ªÉm th·ª≠:** 10.000 ·∫£nh ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh.\n"
        "- **Ph√¢n b·ªë ƒë·ªìng ƒë·ªÅu** gi·ªØa c√°c ch·ªØ s·ªë 0-9 ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh kh√°ch quan."
    )
    
    # C√°c ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n
    st.header("üõ†Ô∏è Ph∆∞∆°ng ph√°p Ti·∫øp C·∫≠n")
    st.subheader("üìå Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng")
    st.write("C√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng ƒë·ªÉ x·ª≠ l√Ω ·∫£nh MNIST:")
    st.markdown("- PCA, HOG, SIFT")
    
    st.subheader("üìå Thu·∫≠t to√°n H·ªçc M√°y")
    st.write("Nh·ªØng thu·∫≠t to√°n c∆° b·∫£n c√≥ th·ªÉ √°p d·ª•ng:")
    st.markdown("- KNN, SVM, Random Forest, Logistic Regression")
    
    st.subheader("üìå H·ªçc S√¢u")
    st.write("C√°c ki·∫øn tr√∫c m·∫°ng n∆°-ron ph·ªï bi·∫øn ƒë·ªÉ x·ª≠ l√Ω MNIST:")
    st.markdown("- MLP, CNN (LeNet-5, AlexNet, ResNet), RNN")
    
    

def up_load_db():
    st.title("üì• MNIST Data Loader")
    
    if "mnist_data" in st.session_state and st.session_state.mnist_data is not None:
        st.success("‚úÖ D·ªØ li·ªáu MNIST ƒë√£ s·∫µn s√†ng!")
    else:
        st.subheader("üîÑ T·∫£i d·ªØ li·ªáu t·ª´ OpenML")
        if st.button("üìÇ T·∫£i MNIST", key="download_mnist"):
            st.info("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu... Vui l√≤ng ch·ªù")
            
            progress = st.progress(0)
            status_text = st.empty()
            for i in range(100):
                time.sleep(0.3 / 10)
                progress.progress(i + 1)
                status_text.text(f"‚è≥ ƒêang t·∫£i... {i + 1}%")
            
            X = np.load("X.npy")
            y = np.load("y.npy")
            
            st.session_state.mnist_data = (X, y)
            st.success("‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
            progress.empty()
            status_text.empty()
    
    if "mnist_data" in st.session_state and st.session_state.mnist_data is not None:
        X, y = st.session_state.mnist_data
        st.subheader("üé® Xem tr∆∞·ªõc d·ªØ li·ªáu")
        fig, axes = plt.subplots(1, 5, figsize=(10, 2))
        for i in range(5):
            axes[i].imshow(X[i].reshape(28, 28), cmap='gray')
            axes[i].set_title(f"D·ª± ƒëo√°n: {y[i]}", fontsize=10)
            axes[i].axis('off')
        st.pyplot(fig)
        
        st.subheader("üõ†Ô∏è Ch·ªçn ph∆∞∆°ng ph√°p ti·ªÅn x·ª≠ l√Ω")
        preprocess = st.radio("Ch·ªçn ph∆∞∆°ng ph√°p:", ["Kh√¥ng x·ª≠ l√Ω", "Chu·∫©n h√≥a", "Ti√™u chu·∫©n h√≥a", "X·ª≠ l√Ω thi·∫øu"], index=0)
        
        X_reshaped = X.reshape(X.shape[0], -1)
        progress = st.progress(0)
        
        for i in range(100):
            time.sleep(0.2 / 10)
            progress.progress(i + 1)
        
        if preprocess == "Chu·∫©n h√≥a":
            X_processed = MinMaxScaler().fit_transform(X_reshaped)
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a!")
        elif preprocess == "Ti√™u chu·∫©n h√≥a":
            X_processed = StandardScaler().fit_transform(X_reshaped)
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ti√™u chu·∫©n h√≥a!")
        elif preprocess == "X·ª≠ l√Ω thi·∫øu":
            X_processed = SimpleImputer(strategy='mean').fit_transform(X_reshaped)
            st.success("‚úÖ D·ªØ li·ªáu thi·∫øu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω!")
        else:
            X_processed = X_reshaped
            st.info("üîπ Kh√¥ng th·ª±c hi·ªán ti·ªÅn x·ª≠ l√Ω")
        
        fig, axes = plt.subplots(1, 5, figsize=(10, 2))
        for i in range(5):
            axes[i].imshow(X_processed[i].reshape(28, 28), cmap='gray')
            axes[i].set_title(f"D·ª± ƒëo√°n: {y[i]}", fontsize=10)
            axes[i].axis('off')
        st.pyplot(fig)
        
        progress.empty()
    else:
        st.warning("‚ö†Ô∏è H√£y t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c!")

    if __name__ == "__main__":
        load_mnist_data

def chia_du_lieu():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")

    # Load d·ªØ li·ªáu
    X = np.load("X.npy")
    y = np.load("y.npy")
    total_samples = X.shape[0]

    # Ki·ªÉm tra tr·∫°ng th√°i session
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh train
    num_samples = st.slider("üìå S·ªë l∆∞·ª£ng m·∫´u train:", 1000, total_samples, 10000)

    # Ch·ªçn t·ª∑ l·ªá t·∫≠p test & validation
    test_ratio = st.slider("üìå T·ª∑ l·ªá % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_ratio = 100 - test_ratio
    val_ratio = st.slider("üìå T·ª∑ l·ªá % Validation trong t·∫≠p Train", 0, 50, 15)

    # Hi·ªÉn th·ªã th√¥ng tin ph√¢n chia
    train_ratio = remaining_ratio - val_ratio
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Train={train_ratio}%, Validation={val_ratio}%, Test={test_ratio}%")

    # Khi nh·∫•n n√∫t x√°c nh·∫≠n
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True  

        # Chia t·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)

        # Chia t·∫≠p Train/Test
        stratify_opt = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_ratio / 100, stratify=stratify_opt, random_state=42
        )

        # Chia t·∫≠p Train/Validation
        stratify_opt = y_train_full if len(np.unique(y_train_full)) > 1 else None
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_ratio / (100 - test_ratio),
            stratify=stratify_opt, random_state=42
        )

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.update({
            "total_samples": num_samples,
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test,
            "train_size": X_train.shape[0], "val_size": X_val.shape[0], "test_size": X_test.shape[0]
        })

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ chia d·ªØ li·ªáu
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ chia th√†nh c√¥ng!")
        st.table(pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        }))

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")




def train():
    """Hu·∫•n luy·ªán m√¥ h√¨nh Decision Tree ho·∫∑c SVM v√† l∆∞u tr√™n MLflow v·ªõi thanh ti·∫øn tr√¨nh hi·ªÉn th·ªã %."""
    mlflow_input()

    # üì• Ki·ªÉm tra d·ªØ li·ªáu
    if not all(key in st.session_state for key in ["X_train", "y_train", "X_test", "y_test"]):
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    X_train, y_train = st.session_state["X_train"], st.session_state["y_train"]
    X_test, y_test = st.session_state["X_test"], st.session_state["y_test"]

    # üåü Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train, X_test = X_train.reshape(-1, 28 * 28) / 255.0, X_test.reshape(-1, 28 * 28) / 255.0

    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    # üìå ƒê·∫∑t t√™n th√≠ nghi·ªám
    experiment_name = st.text_input("üìå ƒê·∫∑t t√™n th√≠ nghi·ªám:", "default_experiment", 
                                    help="T√™n c·ªßa th√≠ nghi·ªám ƒë·ªÉ d·ªÖ d√†ng qu·∫£n l√Ω tr√™n MLflow.")

    # üìå L·ª±a ch·ªçn m√¥ h√¨nh
    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Decision Tree", "SVM"])
    
    if model_choice == "Decision Tree":
        criterion = st.selectbox("Criterion (H√†m m·∫•t m√°t: Gini/Entropy) ", ["gini", "entropy"])
        max_depth = st.slider("max_depth", 1, 20, 5, help="Gi·ªõi h·∫°n ƒë·ªô s√¢u c·ªßa c√¢y ƒë·ªÉ tr√°nh overfitting.")
        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)
    else:
        C = st.slider("C (H·ªá s·ªë ƒëi·ªÅu chu·∫©n)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel (H√†m nh√¢n)", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    # üìå Ch·ªçn s·ªë folds cho KFold Cross-Validation
    k_folds = st.slider("S·ªë folds", 2, 10, 5, help="S·ªë t·∫≠p chia ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh.")

    # üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán
    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
            progress_bar = st.progress(0)
            percent_text = st.empty()  # Ch·ªó hi·ªÉn th·ªã %

            with mlflow.start_run(run_name=experiment_name):
                kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
                cv_scores = []

                # V√≤ng l·∫∑p Cross-Validation
                for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):
                    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]
                    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]

                    model.fit(X_train_fold, y_train_fold)
                    val_pred = model.predict(X_val_fold)
                    val_acc = accuracy_score(y_val_fold, val_pred)
                    cv_scores.append(val_acc)
                    mlflow.log_metric("cv_accuracy", val_acc, step=fold)

                    # C·∫≠p nh·∫≠t thanh tr·∫°ng th√°i (b·ªè qua hi·ªÉn th·ªã t·ª´ng fold)
                    percent_done = int(((fold + 1) / k_folds) * 70)
                    progress_bar.progress(percent_done)
                    percent_text.write(f"**Ti·∫øn ƒë·ªô: {percent_done}%**")

                    time.sleep(1)  

                # K·∫øt qu·∫£ CV
                cv_accuracy_mean = np.mean(cv_scores)
                cv_accuracy_std = np.std(cv_scores)
                st.success(f"‚úÖ **Cross-Validation Accuracy:** {cv_accuracy_mean:.4f} ¬± {cv_accuracy_std:.4f}")

                # Hu·∫•n luy·ªán tr√™n to√†n b·ªô t·∫≠p train
                model.fit(X_train, y_train)

                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh (85%)
                progress_bar.progress(85)
                percent_text.write("**Ti·∫øn ƒë·ªô: 85%**")

                # D·ª± ƒëo√°n tr√™n test set
                y_pred = model.predict(X_test)
                test_acc = accuracy_score(y_test, y_pred)
                mlflow.log_metric("test_accuracy", test_acc)
                st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n test set:** {test_acc:.4f}")

                # Delay th√™m 20s tr∆∞·ªõc khi ho√†n th√†nh
                for i in range(1, 21):
                    progress_percent = 85 + (i // 2)
                    progress_bar.progress(progress_percent)
                    percent_text.write(f"**Ti·∫øn ƒë·ªô: {progress_percent}%**")
                    time.sleep(1)

                # Ho√†n th√†nh ti·∫øn tr√¨nh
                progress_bar.progress(100)
                percent_text.write("‚úÖ **Ti·∫øn ƒë·ªô: 100% - Ho√†n th√†nh!**")

                # Log tham s·ªë v√†o MLflow
                mlflow.log_param("experiment_name", experiment_name)
                mlflow.log_param("model", model_choice)
                mlflow.log_param("k_folds", k_folds)
                if model_choice == "Decision Tree":
                    mlflow.log_param("criterion", criterion)
                    mlflow.log_param("max_depth", max_depth)
                else:
                    mlflow.log_param("C", C)
                    mlflow.log_param("kernel", kernel)

                mlflow.log_metric("cv_accuracy_mean", cv_accuracy_mean)
                mlflow.log_metric("cv_accuracy_std", cv_accuracy_std)
                mlflow.sklearn.log_model(model, model_choice.lower())

                st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **{experiment_name}**!")
                st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")


def mlflow_input():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    DAGSHUB_USERNAME = "NguyenNhat248"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "Mnist"
    DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Classifications")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


def load_model(path):
    try:
        return joblib.load(path)
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i `{path}`")
        st.stop()

def preprocess_canvas_image(canvas_result):
    """X·ª≠ l√Ω ·∫£nh t·ª´ canvas: chuy·ªÉn grayscale, resize 8x8 v√† chu·∫©n h√≥a."""
    if canvas_result.image_data is None:
        return None

    # L·∫•y k√™nh alpha (ƒë·ªÉ nh·∫≠n di·ªán n√©t v·∫Ω)
    img = canvas_result.image_data[:, :, 3] * 255  # Chuy·ªÉn alpha v·ªÅ 0-255
    img = Image.fromarray(img.astype(np.uint8))  # Chuy·ªÉn th√†nh ·∫£nh PIL
    
    # Resize v·ªÅ 8x8 (ƒë√∫ng v·ªõi m√¥ h√¨nh SVM digits)
    img = img.resize((8, 8)).convert("L")

    # Chuy·ªÉn sang numpy array, chu·∫©n h√≥a v·ªÅ [0, 16] (gi·ªëng sklearn digits dataset)
    img = np.array(img, dtype=np.float32)
    img = img / img.max() * 16  # Normalize v·ªÅ [0, 16]

    return img.flatten().reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D c√≥ 64 features


def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")


def show_mlflow_experiments():
    """Xem danh s√°ch Runs trong MLflow."""
    st.title("üìä MLflow Experiment Viewer")

    mlflow_input()

    experiment_target = "Classifications"
    available_experiments = mlflow.search_experiments()
    chosen_experiment = next((exp for exp in available_experiments if exp.name == experiment_target), None)

    if not chosen_experiment:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y Experiment '{experiment_target}'!")
        return

    st.subheader(f"üìå Experiment: {experiment_target}")
    st.write(f"**Experiment ID:** {chosen_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if chosen_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**L∆∞u tr·ªØ t·∫°i:** {chosen_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs t·ª´ MLflow
    experiment_runs = mlflow.search_runs(experiment_ids=[chosen_experiment.experiment_id])

    if experiment_runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    # X·ª≠ l√Ω danh s√°ch Runs
    runs_list = []
    for _, run_entry in experiment_runs.iterrows():
        run_id = run_entry["run_id"]
        run_details = mlflow.get_run(run_id)
        run_tags = run_details.data.tags
        run_display_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")
        run_creation_time = format_time_relative(run_details.info.start_time)
        run_duration = (run_details.info.end_time - run_details.info.start_time) / 1000 if run_details.info.end_time else "ƒêang ch·∫°y"
        run_origin = run_tags.get("mlflow.source.name", "Unknown")

        runs_list.append({
            "Run Name": run_display_name,
            "Run ID": run_id,
            "Created": run_creation_time,
            "Duration (s)": run_duration if isinstance(run_duration, str) else f"{run_duration:.1f}s",
            "Source": run_origin
        })

    # S·∫Øp x·∫øp runs theo th·ªùi gian t·∫°o (g·∫ßn nh·∫•t tr∆∞·ªõc)
    runs_dataframe = pd.DataFrame(runs_list).sort_values(by="Created", ascending=False)

    # Hi·ªÉn th·ªã b·∫£ng danh s√°ch Runs
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(runs_dataframe, use_container_width=True)

    # Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt
    available_run_names = runs_dataframe["Run Name"].tolist()
    chosen_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", available_run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng v·ªõi Run Name
    chosen_run_id = runs_dataframe.loc[runs_dataframe["Run Name"] == chosen_run_name, "Run ID"].values[0]
    chosen_run = mlflow.get_run(chosen_run_id)

    # --- ‚úèÔ∏è ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    updated_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", chosen_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(chosen_run_id, "mlflow.runName", updated_run_name)
            st.success(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t t√™n th√†nh **{updated_run_name}**. Vui l√≤ng t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as err:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {err}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(chosen_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a Run **{chosen_run_name}**! Vui l√≤ng t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as err:
            st.error(f"‚ùå L·ªói khi x√≥a run: {err}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if chosen_run:
        st.subheader(f"üìå Th√¥ng tin Run: {chosen_run_name}")
        st.write(f"**Run ID:** {chosen_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {chosen_run.info.status}")

        # Chuy·ªÉn ƒë·ªïi timestamp v·ªÅ d·∫°ng th·ªùi gian ƒë·ªçc ƒë∆∞·ª£c
        start_timestamp = chosen_run.info.start_time
        formatted_start_time = datetime.fromtimestamp(start_timestamp / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_timestamp else "Kh√¥ng c√≥ d·ªØ li·ªáu"

        st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {formatted_start_time}")

        # Hi·ªÉn th·ªã parameters v√† metrics
        run_parameters = chosen_run.data.params
        run_metrics = chosen_run.data.metrics

        if run_parameters:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(run_parameters)

        if run_metrics:
            st.write("### üìä Metrics:")
            st.json(run_metrics)

    else:
        st.warning("‚ö† Kh√¥ng c√≥ th√¥ng tin cho Run ƒë√£ ch·ªçn.")


def preprocess_canvas_image(canvas_result):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh v·∫Ω t·ª´ canvas ƒë·ªÉ ph√π h·ª£p v·ªõi m√¥ h√¨nh."""
    if canvas_result.image_data is None:
        return None

    img = canvas_result.image_data[:, :, :3]  # L·∫•y 3 k√™nh m√†u
    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # Chuy·ªÉn sang grayscale
    img = cv2.resize(img, (8, 8))  # Resize v·ªÅ 8x8 pixels
    img = cv2.GaussianBlur(img, (3, 3), 0)  # L√†m m·ªãn ·∫£nh ƒë·ªÉ gi·∫£m nhi·ªÖu
    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)  # ƒê·∫£o ng∆∞·ª£c m√†u (tr·∫Øng n·ªÅn ƒëen)
    
    img = img / 255.0  # Chu·∫©n h√≥a pixel v·ªÅ [0,1]
    img = img.flatten().reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D (1, 64)
    
    return img

def du_doan():
    """Giao di·ªán d·ª± ƒëo√°n s·ªë vi·∫øt tay ho·∫∑c t·∫≠p d·ªØ li·ªáu test."""
    st.title("üî¢ D·ª± ƒëo√°n ch·ªØ s·ªë vi·∫øt tay")
    option = st.radio("Ch·ªçn c√°ch nh·∫≠p d·ªØ li·ªáu:", ["V·∫Ω s·ªë", "T·∫£i l√™n t·∫≠p test"])

    if option == "V·∫Ω s·ªë":
        st.subheader("‚úèÔ∏è V·∫Ω s·ªë v√†o √¥ b√™n d∆∞·ªõi:")
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key="canvas"
        )
    else:
        st.subheader("üìÇ T·∫£i l√™n t·∫≠p d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n")
        file = st.file_uploader("Ch·ªçn file d·ªØ li·ªáu (.csv ho·∫∑c .npy):", type=["csv", "npy"])
        if file:
            data = pd.read_csv(file).values if file.name.endswith(".csv") else np.load(file)
            st.write(f"üìä T·ªïng s·ªë m·∫´u test: {data.shape[0]}")

    # Load m√¥ h√¨nh
    model_path = "svm_mnist_rbf.joblib"
    model = joblib.load(model_path)
    try:
        model = joblib.load(model_path)
        st.success("‚úÖ M√¥ h√¨nh SVM tuy·∫øn t√≠nh ƒë√£ s·∫µn s√†ng!")

        # Ki·ªÉm tra s·ªë l∆∞·ª£ng features m√† m√¥ h√¨nh y√™u c·∫ßu
        print("M√¥ h√¨nh y√™u c·∫ßu s·ªë feature:", model.n_features_in_)
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file `{model_path}`. H√£y ki·ªÉm tra l·∫°i!")
        return

    # N·∫øu ch·ªçn v·∫Ω s·ªë, x·ª≠ l√Ω ·∫£nh t·ª´ canvas
    if option == "V·∫Ω s·ªë" and st.button("üîÆ D·ª± ƒëo√°n"):
        if canvas_result.image_data is not None:
            img = preprocess_canvas_image(canvas_result)

            # Ki·ªÉm tra s·ªë features
            print("Shape of processed image:", img.shape)
            print("M√¥ h√¨nh SVM y√™u c·∫ßu s·ªë feature:", model.n_features_in_)

            if img.shape[1] != model.n_features_in_:
                st.error("‚ö†Ô∏è ·∫¢nh ƒë·∫ßu v√†o kh√¥ng c√≥ ƒë√∫ng s·ªë feature! H√£y ki·ªÉm tra l·∫°i preprocessing.")
                return

            prediction = model.predict(img)
            st.subheader(f"üî¢ K·∫øt qu·∫£ d·ª± ƒëo√°n: {prediction[0]}")
        else:
            st.error("‚ö†Ô∏è Vui l√≤ng v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")

    # N·∫øu t·∫£i l√™n t·∫≠p test
    elif option == "T·∫£i l√™n t·∫≠p test" and file and st.button("üîÆ D·ª± ƒëo√°n to√†n b·ªô"):
        if data.shape[1] != model.n_features_in_:
            st.error(f"‚ö†Ô∏è S·ªë l∆∞·ª£ng features ({data.shape[1]}) kh√¥ng kh·ªõp v·ªõi m√¥ h√¨nh ({model.n_features_in_}).")
            return

        preds = model.predict(data)
        probs = model.decision_function(data) if hasattr(model, 'decision_function') else model.predict_proba(data)
        confidences = np.max(probs, axis=1) if probs is not None else ["Kh√¥ng r√µ"] * len(preds)

        st.write("üìå K·∫øt qu·∫£ tr√™n t·∫≠p d·ªØ li·ªáu test:")
        for i in range(min(10, len(preds))):
            st.write(f"M·∫´u {i+1}: {preds[i]} (ƒê·ªô tin c·∫≠y: {confidences[i]:.2f})")

        # Hi·ªÉn th·ªã 5 ·∫£nh ƒë·∫ßu ti√™n
        fig, axes = plt.subplots(1, min(5, len(data)), figsize=(10, 2))
        for i, ax in enumerate(axes):
            ax.imshow(data[i].reshape(28, 28), cmap="gray")
            ax.set_title(f"{preds[i]} ({confidences[i]:.2f})")
            ax.axis("off")
        st.pyplot(fig)

        



def Classification():
    # Thi·∫øt l·∫≠p CSS ƒë·ªÉ h·ªó tr·ª£ hi·ªÉn th·ªã tabs v·ªõi hi·ªáu ·ª©ng hover v√† thanh cu·ªôn
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
    st.title("üñ•Ô∏è MNIST Classification App")

    # T·∫°o c√°c tab trong giao di·ªán Streamlit
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üìñ L√Ω thuy·∫øt Decision Tree", 
        "üìñ L√Ω thuy·∫øt SVM", 
        "üöÄ Data", 
        "üì• T·∫£i d·ªØ li·ªáu", 
        "‚öôÔ∏è Hu·∫•n luy·ªán", 
        "Tracking mlflow",
        "üîÆ D·ª± ƒëo√°n"
    ])

    # N·ªôi dung c·ªßa t·ª´ng tab
    with tab1:
        ly_thuyet_Decision_tree()

    with tab2:
        ly_thuyet_SVM()
    
    with tab3:
        data()

    with tab4:
        up_load_db()
    
    with tab5:      
        chia_du_lieu()
        train()
    
    with tab6:
        show_mlflow_experiments()  # Thay th·∫ø d√≤ng c≈©


    with tab7:
        du_doan()  # G·ªçi h√†m d·ª± ƒëo√°n ƒë·ªÉ x·ª≠ l√Ω khi v√†o tab D·ª± ƒëo√°n

def run(): 
    Classification()

if __name__ == "__main__":
    run()

