import mlflow
import os
import time
import numpy as np
import pandas as pd
from math import sqrt
from sklearn.datasets import make_regression
import joblib
import datetime
from scipy.stats import zscore
from mlflow.tracking import MlflowClient 
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler 
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st

DAGSHUB_USERNAME = "NguyenNhat248"  # Thay b·∫±ng username c·ªßa b·∫°n
DAGSHUB_REPO_NAME = "Mnist"
DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

def ly_thuyet_mlinear():
    # Ti√™u ƒë·ªÅ ch√≠nh v·ªõi bi·ªÉu t∆∞·ª£ng n·ªïi b·∫≠t
    st.title("üìä H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn & H·ªìi quy ƒëa th·ª©c")

    # Chia th√†nh 2 ph·∫ßn
    tab1, tab2 = st.tabs(["üìà H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn", "üìâ H·ªìi quy ƒëa th·ª©c"])

    with tab1:
        st.subheader("üîπ H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn (Multiple Linear Regression - MLR)")

        # Hi·ªÉn th·ªã l√Ω thuy·∫øt b√™n tr√°i v√† c√¥ng th·ª©c b√™n ph·∫£i
        col1, col2 = st.columns([1.5, 1])

        with col1:
            st.markdown("""
            **Kh√°i ni·ªám:**  
            H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn m·ªü r·ªông t·ª´ h·ªìi quy tuy·∫øn t√≠nh ƒë∆°n bi·∫øn, s·ª≠ d·ª•ng nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p ƒë·ªÉ d·ª± ƒëo√°n bi·∫øn ph·ª• thu·ªôc.
            """)
            st.write("üìå C√¥ng th·ª©c t·ªïng qu√°t:")
        
        with col2:
            st.latex(r"y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon")

        # Danh s√°ch gi·∫£ ƒë·ªãnh c·ªßa m√¥ h√¨nh
        st.markdown("### ‚úÖ Gi·∫£ ƒë·ªãnh c·ªßa MLR")
        st.markdown("""
        - **Tuy·∫øn t√≠nh**: M·ªëi quan h·ªá gi·ªØa bi·∫øn ƒë·ªôc l·∫≠p v√† bi·∫øn ph·ª• thu·ªôc l√† tuy·∫øn t√≠nh.
        - **Kh√¥ng ƒëa c·ªông tuy·∫øn**: C√°c bi·∫øn ƒë·ªôc l·∫≠p kh√¥ng ph·ª• thu·ªôc m·∫°nh v√†o nhau.
        - **Sai s·ªë ph√¢n ph·ªëi chu·∫©n**: Sai s·ªë c√≥ ph√¢n ph·ªëi chu·∫©n v·ªõi trung b√¨nh b·∫±ng 0.
        """)

        # C√¥ng th·ª©c ∆∞·ªõc l∆∞·ª£ng h·ªá s·ªë
        st.write("üìä **∆Ø·ªõc l∆∞·ª£ng tham s·ªë b·∫±ng ph∆∞∆°ng ph√°p OLS:**")
        st.latex(r"\beta = (X^T X)^{-1} X^T Y")

        # Minh h·ªça h·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn
        st.write("### üìà Minh h·ªça MLR:")
        X = np.linspace(0, 10, 100)
        Y = 2 + 3 * X + np.random.randn(100) * 2
        fig, ax = plt.subplots()
        ax.scatter(X, Y, label="D·ªØ li·ªáu th·ª±c t·∫ø")
        ax.plot(X, 2 + 3 * X, color='red', label="ƒê∆∞·ªùng h·ªìi quy")
        ax.set_xlabel("X - Bi·∫øn ƒë·ªôc l·∫≠p")
        ax.set_ylabel("Y - Bi·∫øn ph·ª• thu·ªôc")
        ax.legend()
        st.pyplot(fig)

    with tab2:
        st.subheader("üîπ H·ªìi quy ƒëa th·ª©c (Polynomial Regression)")

        st.markdown("""
        **Kh√°i ni·ªám:**  
        H·ªìi quy ƒëa th·ª©c l√† m·ªôt d·∫°ng m·ªü r·ªông c·ªßa h·ªìi quy tuy·∫øn t√≠nh, trong ƒë√≥ bi·∫øn ƒë·ªôc l·∫≠p ƒë∆∞·ª£c n√¢ng l√™n l≈©y th·ª´a ƒë·ªÉ ph√π h·ª£p v·ªõi d·ªØ li·ªáu phi tuy·∫øn.
        """)

        st.write("üìå C√¥ng th·ª©c h·ªìi quy ƒëa th·ª©c:")
        st.latex(r"y = w_0 + w_1 x + w_2 x^2 + ... + w_d x^d + \epsilon")

        # Minh h·ªça h·ªìi quy ƒëa th·ª©c
        st.write("### üìâ Minh h·ªça H·ªìi quy ƒëa th·ª©c:")
        X_poly = np.linspace(-3, 3, 100)
        Y_poly = 2 + 1.5 * X_poly - 0.5 * X_poly**2 + np.random.randn(100) * 2
        fig_poly, ax_poly = plt.subplots()
        ax_poly.scatter(X_poly, Y_poly, label="D·ªØ li·ªáu th·ª±c t·∫ø")
        ax_poly.plot(X_poly, 2 + 1.5 * X_poly - 0.5 * X_poly**2, color='green', label="ƒê∆∞·ªùng h·ªìi quy ƒëa th·ª©c")
        ax_poly.set_xlabel("X - Bi·∫øn ƒë·ªôc l·∫≠p")
        ax_poly.set_ylabel("Y - Bi·∫øn ph·ª• thu·ªôc")
        ax_poly.legend()
        st.pyplot(fig_poly)


## ----------------------------------- UPLOAD_DB ------------------------------
def up_load_db():
    st.header("Ph√¢n t√≠ch v√† x·ª≠ l√Ω d·ªØ li·ªáu")
    
    # üì• T·∫£i d·ªØ li·ªáu
    with st.expander("üì• T·∫£i d·ªØ li·ªáu", expanded=True):
        uploaded_file = st.file_uploader("T·∫£i file CSV (Titanic dataset)", type=["csv"])
        if uploaded_file is not None:
            st.session_state.df = pd.read_csv(uploaded_file)
            st.write("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n:")
            st.write(st.session_state.df.head(10))
            st.session_state.data_loaded = True

    # üîç Ki·ªÉm tra d·ªØ li·ªáu
    with st.expander("üîç Ki·ªÉm tra d·ªØ li·ªáu"):
        if st.session_state.get("data_loaded", False):
            df = st.session_state.df

            # T√≠nh s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu
            missing_values = df.isnull().sum()

            # X√°c ƒë·ªãnh outliers b·∫±ng Z-score
            outlier_count = {
                col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
                for col in df.select_dtypes(include=['number']).columns
            }

            # T·∫°o b√°o c√°o l·ªói
            error_report = pd.DataFrame({
                "C·ªôt": df.columns,
                "Gi√° tr·ªã thi·∫øu": missing_values.values,
                "Outlier": [outlier_count.get(col, 0) for col in df.columns]
            })

            # Hi·ªÉn th·ªã b·∫£ng b√°o c√°o v·ªõi chi·ªÅu r·ªông t·ªëi ƒëa
            st.write("**Gi√° tr·ªã thi·∫øu v√† Outlier:**")
            st.table(error_report)
        else:
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")

    # ‚öôÔ∏è X·ª≠ l√Ω d·ªØ li·ªáu
    with st.expander("‚öôÔ∏è X·ª≠ l√Ω d·ªØ li·ªáu"):
        if st.session_state.get("data_loaded", False):
            df = st.session_state.df.copy()

            # Lo·∫°i b·ªè c·ªôt
            dropped_cols = st.multiselect("Ch·ªçn c·ªôt c·∫ßn lo·∫°i b·ªè:", df.columns.tolist(), default=["PassengerId", "Name", "Ticket", "Cabin"])
            df.drop(columns=dropped_cols, errors='ignore', inplace=True)
            st.write(f"ƒê√£ lo·∫°i b·ªè c√°c c·ªôt: {', '.join(dropped_cols)}")

            # ƒêi·ªÅn gi√° tr·ªã thi·∫øu
            st.write("ƒêi·ªÅn gi√° tr·ªã thi·∫øu:")
            fill_missing_cols = st.multiselect("Ch·ªçn c·ªôt ƒë·ªÉ ƒëi·ªÅn gi√° tr·ªã thi·∫øu:", df.columns.tolist())
            for col in fill_missing_cols:
                if df[col].isnull().any():
                    method = st.selectbox(f"Ph∆∞∆°ng ph√°p ƒëi·ªÅn cho c·ªôt {col}:", 
                                          options=["Median", "Mean", "Lo·∫°i b·ªè"], 
                                          key=f"fill_{col}")
                    if df[col].dtype in ['float64', 'int64']:
                        if method == "Trung v·ªã (median)":
                            df[col].fillna(df[col].median(), inplace=True)
                        elif method == "Trung b√¨nh (mean)":
                            df[col].fillna(df[col].mean(), inplace=True)
                        elif method == "Lo·∫°i b·ªè":
                            df.dropna(subset=[col], inplace=True)
                    else:
                        if method == "Mode":
                            df[col].fillna(df[col].mode()[0], inplace=True)
                        elif method == "Lo·∫°i b·ªè":
                            df.dropna(subset=[col], inplace=True)

            # M√£ h√≥a bi·∫øn ph√¢n lo·∫°i
            st.write("M√£ h√≥a c√°c bi·∫øn ph√¢n lo·∫°i:")
            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
            cols_to_encode = st.multiselect("Ch·ªçn c·ªôt ƒë·ªÉ m√£ h√≥a:", categorical_cols)
            for col in cols_to_encode:
                df[col] = df[col].astype('category').cat.codes
                st.write(f"ƒê√£ m√£ h√≥a c·ªôt {col}.")

            # Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
            st.write("Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë:")
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
            if "Survived" in numeric_cols:
                numeric_cols.remove("Survived")  # Kh√¥ng chu·∫©n h√≥a c·ªôt nh√£n

            if numeric_cols:  # Ki·ªÉm tra n·∫øu c√≥ c·ªôt s·ªë ƒë·ªÉ chu·∫©n h√≥a
                norm_method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p chu·∫©n h√≥a:", ["Min-Max Scaling", "Standard Scaling"], key="norm_method")
                if norm_method == "Min-Max Scaling":
                    scaler = MinMaxScaler()
                else:
                    scaler = StandardScaler()

                df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
                st.write(f"ƒê√£ chu·∫©n h√≥a c√°c c·ªôt s·ªë: {', '.join(numeric_cols)}")

            # C·∫≠p nh·∫≠t l·∫°i d·ªØ li·ªáu
            st.session_state.df = df
            st.session_state.data_processed = True

            # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau x·ª≠ l√Ω
            st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω!")
            st.write(df.head(10))
        else:
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")


## -----------------------------------  LOGIN ACCOUNT MLFLOW  ------------------------------


def mlflow_input():
    """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MLflow tr√™n DagsHub."""
    DAGSHUB_USERNAME = "NguyenNhat248"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "Mnist"
    DAGSHUB_TOKEN = "4dd0f9a2823d65298c4840f778a4090d794b30d5"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI c·ªßa MLflow tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng c√°ch ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng
    import os
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám
    mlflow.set_experiment("Linear Regressions")

    # L∆∞u link MLflow v√†o session_state ƒë·ªÉ d√πng sau
    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


## ----------------------------------- SPLIT SIZE DATASET ------------------------------
def chia_du_lieu():
    st.title("üìä Chia d·ªØ li·ªáu Train - Validation - Test")

    # Gi·ªõi thi·ªáu quy tr√¨nh chia d·ªØ li·ªáu
    st.markdown("""
    **üîπ T·∫°i sao c·∫ßn chia d·ªØ li·ªáu?**  
    Chia d·ªØ li·ªáu gi√∫p ki·ªÉm tra t√≠nh t·ªïng qu√°t c·ªßa m√¥ h√¨nh:
    - **Train (70%)**: Hu·∫•n luy·ªán m√¥ h√¨nh.
    - **Validation (15%)**: Tinh ch·ªânh tham s·ªë.
    - **Test (15%)**: ƒê√°nh gi√° cu·ªëi c√πng.
    """)

    # Ki·ªÉm tra d·ªØ li·ªáu
    if "df" not in st.session_state:
        st.error("‚ùå D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c t·∫£i l√™n! Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")
        st.stop()

    df = st.session_state.df  # L·∫•y d·ªØ li·ªáu t·ª´ session_state

    # T√πy ch·ªânh t·ª∑ l·ªá chia d·ªØ li·ªáu
    col1, col2 = st.columns(2)
    with col1:
        test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20, step=5)
    with col2:
        val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation", 0, 50, 15, step=5)

    remaining_size = 100 - test_size
    train_size = remaining_size - val_size

    st.write(f"üìä **T·ª∑ l·ªá ph√¢n chia:** Train={train_size}%, Validation={val_size}%, Test={test_size}%")

    # Hi·ªÉn th·ªã ti·∫øn tr√¨nh chia d·ªØ li·ªáu
    if st.button("‚úÖ X√°c nh·∫≠n Chia"):
        progress_bar = st.progress(0)
        progress_text = st.empty()

        # Chia d·ªØ li·ªáu theo t·ª∑ l·ªá ƒë√£ ch·ªçn
        progress_bar.progress(30)
        progress_text.text("üîÑ ƒêang chia t·∫≠p Test...")
        time.sleep(0.5)
        train_full, test = train_test_split(df, test_size=test_size / 100, random_state=42)

        progress_bar.progress(70)
        progress_text.text("üîÑ ƒêang chia t·∫≠p Train v√† Validation...")
        time.sleep(0.5)
        train, val = train_test_split(train_full, test_size=val_size / (100 - test_size), random_state=42)

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.train = train
        st.session_state.test = test
        st.session_state.val = val

        # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [train.shape[0], val.shape[0], test.shape[0]]
        })
        st.table(summary_df)

        # Bi·ªÉu ƒë·ªì minh h·ªça t·ª∑ l·ªá d·ªØ li·ªáu
        labels = ["Train", "Validation", "Test"]
        sizes = [train_size, val_size, test_size]
        colors = ["#2E86C1", "#F1C40F", "#E74C3C"]

        fig, ax = plt.subplots()
        ax.pie(sizes, labels=labels, autopct="%1.1f%%", colors=colors, startangle=90, wedgeprops={"edgecolor": "white"})
        ax.axis("equal")  # Hi·ªÉn th·ªã pie chart theo h√¨nh tr√≤n

        st.pyplot(fig)

        # Ho√†n th√†nh ti·∫øn tr√¨nh
        progress_bar.progress(100)
        progress_text.text("‚úÖ Chia d·ªØ li·ªáu ho√†n th√†nh!")
        st.success("üéâ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")



def train_polynomial_regression(X_train, y_train, degree=2, learning_rate=0.001, n_iterations=500):
    """Hu·∫•n luy·ªán h·ªìi quy ƒëa th·ª©c b·∫±ng Gradient Descent k√®m hi·ªÉn th·ªã ti·∫øn tr√¨nh & bi·ªÉu ƒë·ªì l·ªói."""
    
    st.subheader("üéØ Hu·∫•n luy·ªán h·ªìi quy ƒëa th·ª©c")
    
    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu n·∫øu l√† Pandas
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # T·∫°o ƒë·∫∑c tr∆∞ng ƒëa th·ª©c (kh√¥ng bao g·ªìm t∆∞∆°ng t√°c)
    X_poly = np.hstack([X_train] + [X_train**d for d in range(2, degree + 1)])

    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = StandardScaler()
    X_poly = scaler.fit_transform(X_poly)

    # Th√™m bias (x0 = 1)
    m, n = X_poly.shape
    X_b = np.c_[np.ones((m, 1)), X_poly]

    # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n
    w = np.random.randn(n + 1, 1) * 0.01

    # Gradient Descent
    loss_history = []
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)
        
        if np.isnan(gradients).any():
            st.error("‚ùå Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra d·ªØ li·ªáu ho·∫∑c learning rate.")
            return None
        
        w -= learning_rate * gradients
        
        # T√≠nh to√°n l·ªói trung b√¨nh b√¨nh ph∆∞∆°ng (MSE) ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
        mse = np.mean((X_b.dot(w) - y_train) ** 2)
        loss_history.append(mse)

        if iteration % 50 == 0:
            progress_bar.progress(iteration / n_iterations)
            progress_text.text(f"üîÑ ƒêang hu·∫•n luy·ªán... ({iteration}/{n_iterations})")

    progress_bar.progress(100)
    progress_text.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì l·ªói gi·∫£m d·∫ßn
    st.write("üìâ **Bi·ªÉu ƒë·ªì MSE qua c√°c v√≤ng l·∫∑p:**")
    fig, ax = plt.subplots()
    ax.plot(range(n_iterations), loss_history, color="red")
    ax.set_xlabel("S·ªë v√≤ng l·∫∑p")
    ax.set_ylabel("MSE")
    ax.set_title("Qu√° tr√¨nh gi·∫£m l·ªói trong Gradient Descent")
    st.pyplot(fig)

    return w


def train_multiple_linear_regression(X_train, y_train, learning_rate=0.001, n_iterations=200):
    """Hu·∫•n luy·ªán h·ªìi quy tuy·∫øn t√≠nh b·ªôi b·∫±ng Gradient Descent v·ªõi ti·∫øn tr√¨nh & bi·ªÉu ƒë·ªì l·ªói."""

    st.subheader("üìà Hu·∫•n luy·ªán h·ªìi quy tuy·∫øn t√≠nh b·ªôi")

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # Ki·ªÉm tra d·ªØ li·ªáu c√≥ NaN ho·∫∑c Inf kh√¥ng
    if np.isnan(X_train).any() or np.isnan(y_train).any():
        st.error("‚ùå D·ªØ li·ªáu ch·ª©a NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o.")
        return None
    if np.isinf(X_train).any() or np.isinf(y_train).any():
        st.error("‚ùå D·ªØ li·ªáu ch·ª©a gi√° tr·ªã v√¥ c√πng! H√£y ki·ªÉm tra l·∫°i.")
        return None

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)

    # Th√™m bias
    m, n = X_train.shape
    X_b = np.c_[np.ones((m, 1)), X_train]

    # Kh·ªüi t·∫°o tr·ªçng s·ªë
    w = np.random.randn(n + 1, 1) * 0.01

    # Gradient Descent
    loss_history = []
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

        if np.isnan(gradients).any():
            st.error("‚ùå Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra learning rate.")
            return None

        w -= learning_rate * gradients

        # T√≠nh to√°n l·ªói
        mse = np.mean((X_b.dot(w) - y_train) ** 2)
        loss_history.append(mse)

        if iteration % 50 == 0:
            progress_bar.progress(iteration / n_iterations)
            progress_text.text(f"üîÑ ƒêang hu·∫•n luy·ªán... ({iteration}/{n_iterations})")

    progress_bar.progress(100)
    progress_text.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì l·ªói
    st.write("üìâ **Bi·ªÉu ƒë·ªì MSE qua c√°c v√≤ng l·∫∑p:**")
    fig, ax = plt.subplots()
    ax.plot(range(n_iterations), loss_history, color="blue")
    ax.set_xlabel("S·ªë v√≤ng l·∫∑p")
    ax.set_ylabel("MSE")
    ax.set_title("Qu√° tr√¨nh gi·∫£m l·ªói trong Gradient Descent")
    st.pyplot(fig)

    return w

def train_and_log_model():
    """Giao di·ªán Streamlit ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy v√† log k·∫øt qu·∫£ l√™n MLflow."""
    
    st.title("üìà Hu·∫•n luy·ªán m√¥ h√¨nh H·ªìi quy")

    # Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MLflow
    mlflow_input()

    # Ch·ªçn lo·∫°i m√¥ h√¨nh
    model_type = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh:", ["H·ªìi quy tuy·∫øn t√≠nh b·ªôi", "H·ªìi quy ƒëa th·ª©c"])
    
    # N·∫øu ch·ªçn h·ªìi quy ƒëa th·ª©c, cho ph√©p ch·ªçn b·∫≠c c·ªßa ƒëa th·ª©c
    degree = 2
    if model_type == "H·ªìi quy ƒëa th·ª©c":
        degree = st.slider("üéö Ch·ªçn b·∫≠c c·ªßa ƒëa th·ª©c:", min_value=2, max_value=5, value=2)
    
    # Ch·ªçn hyperparameters
    learning_rate = st.number_input("‚ö° Learning rate:", min_value=0.0001, max_value=0.1, value=0.001, step=0.0001, format="%.4f")
    n_iterations = st.number_input("üîÑ S·ªë l·∫ßn l·∫∑p:", min_value=100, max_value=1000, value=200, step=50)
    n_splits = st.number_input("üìä S·ªë folds cho KFold Cross-Validation:", min_value=2, max_value=10, value=5, step=1)
    
    # N√∫t ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        progress_bar = st.progress(0)
        progress_text = st.empty()

        st.write("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh...")

        # T·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p ƒë·ªÉ hu·∫•n luy·ªán
        X, y = make_regression(n_samples=100, n_features=2, noise=0.1)

        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
        mse_scores, rmse_scores, r2_scores = [], [], []
        
        with mlflow.start_run() as run:
            for fold_idx, (train_index, test_index) in enumerate(kf.split(X)):
                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = y[train_index], y[test_index]
                
                # Chu·∫©n h√≥a d·ªØ li·ªáu
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # Ch·ªçn m√¥ h√¨nh
                if model_type == "H·ªìi quy ƒëa th·ª©c":
                    model = train_polynomial_regression(X_train_scaled, y_train, degree, learning_rate, n_iterations)
                else:
                    model = train_multiple_linear_regression(X_train_scaled, y_train, learning_rate, n_iterations)

                # Th√™m bias v√†o X_test
                if model_type == "H·ªìi quy ƒëa th·ª©c":
                    X_test_poly = np.hstack([X_test_scaled] + [X_test_scaled**d for d in range(2, degree + 1)])
                    X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test_poly]
                else:
                    X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test_scaled]

                # D·ª± ƒëo√°n gi√° tr·ªã
                y_pred = X_b_test.dot(model)

                # T√≠nh metrics
                mse = mean_squared_error(y_test, y_pred)
                rmse = sqrt(mse)
                r2 = r2_score(y_test, y_pred)
                
                mse_scores.append(mse)
                rmse_scores.append(rmse)
                r2_scores.append(r2)

                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh
                progress = int(((fold_idx + 1) / n_splits) * 100)
                progress_bar.progress(progress)
                progress_text.text(f"üîÑ Ti·∫øn tr√¨nh: {progress}% - Hu·∫•n luy·ªán Fold {fold_idx + 1}/{n_splits}")

                time.sleep(0.5)  # Gi·∫£ l·∫≠p th·ªùi gian ch·ªù hu·∫•n luy·ªán

            # Log gi√° tr·ªã trung b√¨nh c·ªßa c√°c metrics l√™n MLflow
            mlflow.log_metrics({
                "MSE": np.mean(mse_scores),
                "RMSE": np.mean(rmse_scores),
                "R2_score": np.mean(r2_scores)
            })

            # L∆∞u m√¥ h√¨nh
            model_dir = "saved_models"
            os.makedirs(model_dir, exist_ok=True)
            model_filename = f"{model_dir}/{model_type.replace(' ', '_').lower()}_model.pkl"
            joblib.dump(model, model_filename)

            # Log m√¥ h√¨nh l√™n MLflow
            mlflow.log_artifact(model_filename)

            # L·∫•y link MLflow
            run_id = run.info.run_id
            mlflow_run_url = f"{st.session_state['mlflow_url']}/#/experiments/0/runs/{run_id}"
            
            # ‚úÖ Hi·ªÉn th·ªã k·∫øt qu·∫£ tr√™n Streamlit
            st.subheader("üìä K·∫øt qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh")
            st.write(f"‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: `{model_filename}`")
            st.markdown(f"üîó **T·∫£i m√¥ h√¨nh:** [Download {model_filename}](./{model_filename})")
            st.markdown(f"üîó **MLflow Tracking:** [Xem k·∫øt qu·∫£ tr√™n MLflow]({mlflow_run_url})")
            
            progress_bar.progress(100)
            progress_text.text("‚úÖ Ti·∫øn tr√¨nh: 100% - Ho√†n th√†nh hu·∫•n luy·ªán!")
            st.success("‚úÖ Hu·∫•n luy·ªán v√† logging ho√†n t·∫•t!")


##------------------------------------ TRACKING MLFLOW -------------------------------
def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow v·ªõi thanh tr·∫°ng th√°i ti·∫øn tr√¨nh."""
    st.title("üìä MLflow Experiment Viewer")

    # L·∫•y danh s√°ch th√≠ nghi·ªám
    experiment_name = "Linear Regressions"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # --- üèÉ‚Äç‚ôÇÔ∏è L·∫•y danh s√°ch Runs v·ªõi thanh tr·∫°ng th√°i ---
    st.write("### üîÑ ƒêang t·∫£i danh s√°ch Runs...")
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    total_runs = len(runs)
    run_info = []
    
    progress_bar = st.progress(0)  # Thanh ti·∫øn tr√¨nh

    for i, (_, run) in enumerate(runs.iterrows()):
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # T√™n Run
        created_time = format_time_relative(run_data.info.start_time)
        duration = (run_data.info.end_time - run_data.info.start_time) / 1000 if run_data.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration (s)": duration if isinstance(duration, str) else f"{duration:.1f}s",
            "Source": source
        })

        # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
        progress_bar.progress(int((i + 1) / total_runs * 100))

    progress_bar.empty()  # X√≥a thanh ti·∫øn tr√¨nh khi ho√†n th√†nh

    # S·∫Øp x·∫øp v√† hi·ªÉn th·ªã b·∫£ng danh s√°ch Runs
    run_info_df = pd.DataFrame(run_info).sort_values(by="Created", ascending=False)
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Ch·ªçn Run t·ª´ dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]
    selected_run = mlflow.get_run(selected_run_id)

    # --- üìù ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{selected_run_name}**! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")

        start_time_ms = selected_run.info.start_time
        start_time = datetime.datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Hi·ªÉn th·ªã model artifact (n·∫øu c√≥)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

def predict_survival():
    df = pd.read_csv("data1.csv")
    features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
    df = df[features + ["Survived"]]

    # X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu
    imputer = SimpleImputer(strategy="median")
    df["Age"] = imputer.fit_transform(df[["Age"]])
    df["Embarked"].fillna(df["Embarked"].mode()[0], inplace=True)

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu d·∫°ng ch·ªØ th√†nh s·ªë
    label_encoders = {}
    for col in ["Sex", "Embarked"]:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

    # Hu·∫•n luy·ªán m√¥ h√¨nh Polynomial Regression b·∫≠c 2
    X = df[features]
    y = df["Survived"]
    poly = PolynomialFeatures(degree=2)
    X_poly = poly.fit_transform(X)
    model = LinearRegression()
    model.fit(X_poly, y)

    # Giao di·ªán Streamlit
    st.title("D·ª± ƒëo√°n kh·∫£ nƒÉng s·ªëng s√≥t tr√™n Titanic")

    pclass = st.selectbox("H·∫°ng v√© (Pclass)", [1, 2, 3])
    sex = st.selectbox("Gi·ªõi t√≠nh", ["male", "female"])
    age = st.number_input("Tu·ªïi", min_value=0, max_value=100, value=30)
    sibsp = st.number_input("S·ªë anh ch·ªã em / v·ª£ ch·ªìng ƒëi c√πng (SibSp)", min_value=0, max_value=10, value=0)
    parch = st.number_input("S·ªë cha m·∫π / con c√°i ƒëi c√πng (Parch)", min_value=0, max_value=10, value=0)
    fare = st.number_input("Gi√° v√© (Fare)", min_value=0.0, max_value=600.0, value=30.0)
    embarked = st.selectbox("C·∫£ng ƒëi (Embarked)", ["C", "Q", "S"])

    if st.button("D·ª± ƒëo√°n"):
        input_data = pd.DataFrame([[pclass, sex, age, sibsp, parch, fare, embarked]], columns=features)
        input_data["Sex"] = label_encoders["Sex"].transform([sex])[0]
        input_data["Embarked"] = label_encoders["Embarked"].transform([embarked])[0]
        
        input_data_poly = poly.transform(input_data)
        prediction = model.predict(input_data_poly)[0]
        survival = "S·ªëng s√≥t" if prediction >= 0.5 else "Kh√¥ng s·ªëng s√≥t"
        
        st.success(f"D·ª± ƒëo√°n: {survival}")
        if prediction >= 0.5:
            st.write("Quy·∫øt ƒë·ªãnh cu·ªëi c√πng: H√†nh kh√°ch n√†y c√≥ kh·∫£ nƒÉng s·ªëng s√≥t.")
        else:
            st.write("Quy·∫øt ƒë·ªãnh cu·ªëi c√πng: H√†nh kh√°ch n√†y kh√¥ng c√≥ kh·∫£ nƒÉng s·ªëng s√≥t.")
        
        # Ki·ªÉm tra xem h√†nh kh√°ch n√†y c√≥ trong t·∫≠p d·ªØ li·ªáu g·ªëc kh√¥ng
        matched = df[
            (df["Pclass"] == pclass) &
            (df["Sex"] == label_encoders["Sex"].transform([sex])[0]) &
            (df["Age"] == age) &
            (df["SibSp"] == sibsp) &
            (df["Parch"] == parch) &
            (df["Fare"] == fare) &
            (df["Embarked"] == label_encoders["Embarked"].transform([embarked])[0])
        ]
        
        if not matched.empty:
            actual_survival = "S·ªëng s√≥t" if matched["Survived"].values[0] == 1 else "Kh√¥ng s·ªëng s√≥t"
            st.info(f"Th√¥ng tin tr√πng kh·ªõp trong t·∫≠p d·ªØ li·ªáu! Th·ª±c t·∫ø: {actual_survival}")
        else:
            st.info("H√†nh kh√°ch n√†y kh√¥ng c√≥ trong t·∫≠p d·ªØ li·ªáu g·ªëc.")



def mt_Regression():
  
    # Thi·∫øt l·∫≠p CSS ƒë·ªÉ h·ªó tr·ª£ hi·ªÉn th·ªã tabs v·ªõi hi·ªáu ·ª©ng hover v√† thanh cu·ªôn
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("üñäÔ∏è Multiple & Polynomial Regression App")

    # Ensure the tab names are properly separated
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìò L√Ω thuy·∫øt MLR & Polynomial Regression", 
    "üì• T·∫£i & ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu",  
    "üîÄ Chia d·ªØ li·ªáu", 
    "ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh", 
    "üîç Th√¥ng tin hu·∫•n luy·ªán",
    "üß† D·ª± ƒëo√°n"
    ])

    with tab1: 
        ly_thuyet_mlinear() 
    with tab2: 
        up_load_db() 
    with tab3: 
        chia_du_lieu() 
    with tab4:
        train_and_log_model() 
    with tab5:
        display_mlflow_experiments() 
    with tab6: 
        predict_survival()

def run():
    mt_Regression()

if __name__ == "__main__": 
    run()

